{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi everyone, \n\nThis is a ready to submit notebook that is relatively easy to understand. \n\nIf you'd like to directly go to a more sophisticated, high scoring notebook, check out the [notebook-part2](https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2)","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom pandas.api.types import CategoricalDtype","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-27T16:28:06.605048Z","iopub.execute_input":"2025-04-27T16:28:06.605365Z","iopub.status.idle":"2025-04-27T16:28:06.609807Z","shell.execute_reply.started":"2025-04-27T16:28:06.605342Z","shell.execute_reply":"2025-04-27T16:28:06.608875Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Read the data\nX = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv',\n                index_col='Id', dtype = {\"MSSubClass\" : \"object\"})\nX_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv',\n                     index_col='Id', dtype = {\"MSSubClass\" : \"object\"})\n#MSSubClass variable is a categorical variable encoded with numbers with arbitrary ordering \n#should be converted to object type so that it is considered as categorical variable\n\nprint(X.shape)\nprint(X_test.shape)\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice\nX.drop(['SalePrice'], axis=1, inplace=True)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X.columns if\n                    X[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\nsmall_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() < 10]\nlarge_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() >= 10]\n\nprint(len(small_cat_categorical_cols))\nprint(len(large_cat_categorical_cols))\nprint(len(categorical_cols))      \n\nprint(X.shape)\nprint(X_test.shape)\n\nprint(categorical_cols)\nprint(numerical_cols)\n\nprint(\"Loaded data\")","metadata":{"execution":{"iopub.status.busy":"2025-04-27T16:28:06.623486Z","iopub.execute_input":"2025-04-27T16:28:06.623982Z","iopub.status.idle":"2025-04-27T16:28:06.698725Z","shell.execute_reply.started":"2025-04-27T16:28:06.623955Z","shell.execute_reply":"2025-04-27T16:28:06.697870Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(1460, 80)\n(1459, 79)\n40\n4\n44\n(1460, 79)\n(1459, 79)\n['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\nLoaded data\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Ordinal categorical features - special handling\nRef : https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices","metadata":{}},{"cell_type":"code","source":"# large_cat_categorical_cols\n# ['MSSubClass', 'Neighborhood', 'Exterior1st', 'Exterior2nd']\n\n#small_cat_categorical_cols\n\n# X.LandSlope.unique()\n# array(['Gtl', 'Mod', 'Sev'], dtype=object)\n\n# X.ExterQual.unique()\n# array(['Gd', 'TA', 'Ex', 'Fa'], dtype=object)\n\n# X.ExterCond.unique()\n# array(['TA', 'Gd', 'Fa', 'Po', 'Ex'], dtype=object)\n\n# X.BsmtQual.unique()\n# array(['Gd', 'TA', 'Ex', nan, 'Fa'], dtype=object)\n\n# X.BsmtCond.unique()\n# array(['TA', 'Gd', nan, 'Fa', 'Po'], dtype=object)\n\n# X.BsmtExposure.unique()\n# array(['No', 'Gd', 'Mn', 'Av', nan], dtype=object)\n\n# X.BsmtFinType1.unique()\n# array(['GLQ', 'ALQ', 'Unf', 'Rec', 'BLQ', nan, 'LwQ'], dtype=object)\n\n# X.BsmtFinType2.unique()\n# array(['Unf', 'BLQ', nan, 'ALQ', 'Rec', 'LwQ', 'GLQ'], dtype=object)\n\n#The above small category columns are clearly ordinal but their default ordering is incorrect. \n# Similar case for HeatingQC, KitchenQual, FireplaceQu, GarageQual, GarageCond, PoolQC\n# Use these as ordinal categories\n\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nordered_levels = {\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"]\n}\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\nordered_levels.keys()\n\nsmall_cat_categorical_cols = list(set(small_cat_categorical_cols).difference(set(ordered_levels.keys())))\n\nfor name, levels in ordered_levels.items():\n    X[name] = X[name].astype(CategoricalDtype(levels, ordered=True))\n    X[name] = X[name].cat.codes\n    X_test[name] = X_test[name].astype(CategoricalDtype(levels, ordered=True))\n    X_test[name] = X_test[name].cat.codes\n\nprint(len(ordered_levels.keys()))\nprint(len(small_cat_categorical_cols))\nprint(len(large_cat_categorical_cols))\nprint(len(categorical_cols))    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:28:06.700214Z","iopub.execute_input":"2025-04-27T16:28:06.700486Z","iopub.status.idle":"2025-04-27T16:28:06.741817Z","shell.execute_reply.started":"2025-04-27T16:28:06.700453Z","shell.execute_reply":"2025-04-27T16:28:06.740948Z"}},"outputs":[{"name":"stdout","text":"14\n26\n4\n44\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Training pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom xgboost import XGBRegressor\n\n# Preprocessing for numerical data\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Preprocessing for categorical data\n\nord_categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('ord_cat', ord_categorical_transformer, list(ordered_levels.keys())),\n        ('small_cat', small_categorical_transformer, small_cat_categorical_cols),\n        ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n    ])\n\n# Define model\nmodel = XGBRegressor(random_state = 0)\n\n#Bundle preprocessing and modeling code in a pipeline\npipeline = Pipeline(steps=[\n   ('preprocessor', preprocessor),\n   ('model', model)\n])","metadata":{"execution":{"iopub.status.busy":"2025-04-27T16:28:06.742802Z","iopub.execute_input":"2025-04-27T16:28:06.743261Z","iopub.status.idle":"2025-04-27T16:28:07.227705Z","shell.execute_reply.started":"2025-04-27T16:28:06.743229Z","shell.execute_reply":"2025-04-27T16:28:07.226955Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Hyperparam search using GridSearchCV","metadata":{}},{"cell_type":"markdown","source":"Uncomment the code in the cell below to identify hyperparameters using GridSearchCV and paste the identified best params onto the full data retrain cell","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# param_grid = {\n#     'model__n_estimators' : [400], \n#     'model__learning_rate' : [0.05],\n#     'model__max_depth' : range(3, 10, 1),\n#     'model__subsample' : np.arange(0.5, 1.05, 0.1),\n#     'model__lambda' : [0, 0.5, 1.0, 1.5, 2.0],\n#     'model__alpha' : [0, 0.5, 1.0, 1.5, 2.0],\n# }  \n\n# gcv = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n# gcv.fit(X, np.log(y))\n\n# print(gcv.best_estimator_)\n# print(gcv.best_score_)\n# print(gcv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T16:28:07.229367Z","iopub.execute_input":"2025-04-27T16:28:07.229697Z","iopub.status.idle":"2025-04-27T16:28:07.234136Z","shell.execute_reply.started":"2025-04-27T16:28:07.229676Z","shell.execute_reply":"2025-04-27T16:28:07.233359Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"**Few of the identified hyperparams and associated scores in the hidden cell below**","metadata":{}},{"cell_type":"code","source":"# param_grid = {\n#     'model__n_estimators' : range(50, 450, 50), \n#     'model__learning_rate' : [0.5, 0.1, 0.05, 0.01],\n# }  \n# gcv = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n# gcv.fit(X, np.log(y))\n# -0.1305179327795296\n# {'model__learning_rate': 0.1, 'model__n_estimators': 350}\n# public score : 0.13731\n\n# param_grid = {\n#     'model__n_estimators' : [350], \n#     'model__learning_rate' : [0.1],\n#     'model__max_depth' : range(3, 10, 1),\n#     'model__subsample' : np.arange(0.5, 1.05, 0.1),\n#     'model__lambda' : [0, 0.5, 1.0, 1.5, 2.0],\n#     'model__alpha' : [0, 0.5, 1.0, 1.5, 2.0],\n# }  \n# -0.12224762414010111\n# {'model__alpha': 0, 'model__lambda': 2.0, 'model__learning_rate': 0.1, 'model__max_depth': 3, \n#  'model__n_estimators': 350, 'model__subsample': 0.7}\n# public score : 0.13744\n\n# param_grid = {\n#     'model__n_estimators' : [350], \n#     'model__learning_rate' : [0.1],\n#     'model__max_depth' : range(3, 10, 1),\n#     'model__subsample' : np.arange(0.5, 1.05, 0.1),\n#     'model__lambda' : [0, 0.5, 1.0, 1.5, 2.0],\n#     'model__alpha' : [0, 0.5, 1.0, 1.5, 2.0],\n# }  \n# used neg_mean_squared_error and\n#     gcv.fit(X, np.log(y))\n#     print(-1 * np.sqrt(-1 * gcv.best_score_))\n# -0.12280028330394728\n# {'model__alpha': 0, 'model__lambda': 2.0, 'model__learning_rate': 0.1, 'model__max_depth': 3, \n#  'model__n_estimators': 350, 'model__subsample': 0.7}\n\n\n# param_grid = {\n#     'model__n_estimators' : range(50, 550, 50), \n#     'model__learning_rate' : [0.5, 0.1, 0.05, 0.01],\n#     'model__max_depth' : [3],\n#     'model__subsample' : [0.7],\n#     'model__lambda' : [2.0],\n#     'model__alpha' : [0],\n# }  \n# -0.12208852576613138\n# {'model__alpha': 0, 'model__lambda': 2.0, 'model__learning_rate': 0.1, \n#  'model__max_depth': 3, 'model__n_estimators': 400, 'model__subsample': 0.7}\n# public score : 0.13709\n\n\n# with ord_categorical_transformer\n# param_grid = {\n#     'model__n_estimators' : [400], \n#     'model__learning_rate' : [0.05],\n#     'model__max_depth' : range(3, 10, 1),\n#     'model__subsample' : np.arange(0.5, 1.05, 0.1),\n#     'model__lambda' : [0, 0.5, 1.0, 1.5, 2.0],\n#     'model__alpha' : [0, 0.5, 1.0, 1.5, 2.0],\n# }  \n# -0.12115739318576706\n# {'model__alpha': 0, 'model__lambda': 1.0, 'model__learning_rate': 0.05, \n#  'model__max_depth': 3, 'model__n_estimators': 400, 'model__subsample': 0.5}\n# public score : 0.13436 with y and prediction\n# public score : 0.13080 with np.log(y) and np.exp(prediction)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T16:28:07.234750Z","iopub.execute_input":"2025-04-27T16:28:07.234959Z","iopub.status.idle":"2025-04-27T16:28:07.254888Z","shell.execute_reply.started":"2025-04-27T16:28:07.234942Z","shell.execute_reply":"2025-04-27T16:28:07.254077Z"},"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Train on full data and obtain test predictions","metadata":{}},{"cell_type":"code","source":"#retrain on full data and obtain test predictions using best model hyperparameter values\n\nbest_params = {'model__alpha': 0, 'model__lambda': 1.0, 'model__learning_rate': 0.05, \n               'model__max_depth': 3, 'model__n_estimators': 400, 'model__subsample': 0.5}\npipeline.set_params(**best_params)\n\npipeline.fit(X, np.log(y))\n\n# Preprocessing of validation data, get predictions\npred = np.exp(pipeline.predict(X_test))\n\nprint(pred[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:28:07.255748Z","iopub.execute_input":"2025-04-27T16:28:07.256071Z","iopub.status.idle":"2025-04-27T16:28:07.833656Z","shell.execute_reply.started":"2025-04-27T16:28:07.256042Z","shell.execute_reply":"2025-04-27T16:28:07.832279Z"}},"outputs":[{"name":"stdout","text":"[121871.44 158508.16 186366.31 188257.86 188758.72 175689.28 168794.78\n 162954.52 182221.11 128713.3 ]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': pred})\noutput.to_csv('submission.csv', index=False)\nprint('saved output file')","metadata":{"execution":{"iopub.status.busy":"2025-04-27T16:28:07.834450Z","iopub.execute_input":"2025-04-27T16:28:07.834688Z","iopub.status.idle":"2025-04-27T16:28:07.850384Z","shell.execute_reply.started":"2025-04-27T16:28:07.834669Z","shell.execute_reply":"2025-04-27T16:28:07.849519Z"},"trusted":true},"outputs":[{"name":"stdout","text":"saved output file\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# References\n- sklearn pipeline : https://www.kaggle.com/code/alexisbcook/pipelines\n- ordinal categorical features : https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices","metadata":{}},{"cell_type":"markdown","source":"# What next","metadata":{}},{"cell_type":"markdown","source":"If you have been able to submit this notebook to the competition, I'm sure you would have seen multiple ways to improve on this.\n\nYou can find plenty of ways to improve using the ideas in this reference notebook : https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices.\n\nIf you found this notebook helpful, please upvote 😄\n\nDo checkout the [notebook-part2](https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2) which describes the approach to obtain a high score.\n\n","metadata":{}}]}