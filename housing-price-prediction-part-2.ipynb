{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook explores different pipeline configurations, performs hyperparameter optimization and model ensembling based on the exploratory analysis from this [notebook](https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2-exploratory)\n\nDo check the [exploratory notebook](https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2-exploratory) if you'd like to get a better idea of data distribution.\n\nPlease upvote if you find this notebook helpful : https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom pandas.api.types import CategoricalDtype\n\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor, VotingRegressor, StackingRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import BayesianRidge, RidgeCV, LinearRegression\n\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\nfrom sklearn.feature_selection import mutual_info_regression\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.base import BaseEstimator, TransformerMixin, clone\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, PowerTransformer\n\nfrom functools import reduce\n\nfrom category_encoders import MEstimateEncoder, cat_boost\n\nfrom sklearn.compose import ColumnTransformer\n\nimport optuna\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-22T11:47:54.431633Z","iopub.execute_input":"2025-04-22T11:47:54.432151Z","iopub.status.idle":"2025-04-22T11:48:00.179142Z","shell.execute_reply.started":"2025-04-22T11:47:54.432101Z","shell.execute_reply":"2025-04-22T11:48:00.177851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import xgboost\n# import lightgbm\n# print(xgboost.__version__)\n# print(lightgbm.__version__)\n\n# 2.0.3\n# 4.5.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.181051Z","iopub.execute_input":"2025-04-22T11:48:00.181991Z","iopub.status.idle":"2025-04-22T11:48:00.187036Z","shell.execute_reply.started":"2025-04-22T11:48:00.181947Z","shell.execute_reply":"2025-04-22T11:48:00.185576Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"SEED = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.189604Z","iopub.execute_input":"2025-04-22T11:48:00.189986Z","iopub.status.idle":"2025-04-22T11:48:00.211740Z","shell.execute_reply.started":"2025-04-22T11:48:00.189957Z","shell.execute_reply":"2025-04-22T11:48:00.210289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load data and preprocess function","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data(train_data = True, perform_impute = True):\n    if train_data:\n        print(\"Train data\")\n        X = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\n        X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n        y = X.SalePrice\n        X.drop(['SalePrice'], axis=1, inplace=True)\n    else:\n        print(\"Test data\")\n        X = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\n        y = None\n    print(\"Loaded data\")\n    print(X.shape)\n\n    X[\"GarageYrBlt\"] = X[\"GarageYrBlt\"].where((X.GarageYrBlt.isna() | (X.GarageYrBlt <= 2024)), X.YearRemodAdd)  #there is 1 GarageYrBlt with value 2207\n    X[\"Exterior2nd\"] = X[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    \n    X = encode(X)\n    if perform_impute:\n        X = impute(X)\n    \n    return (X, y)\n\ndef encode(df):  # lists of columns needed for this is defined in next cell\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name] = df[name].cat.add_categories(\"None\")\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df\n\ndef impute(df):\n    df.loc[df.GarageYrBlt.isna() & df.GarageType.notna(), \"GarageYrBlt\"] = df.YearRemodAdd\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.213069Z","iopub.execute_input":"2025-04-22T11:48:00.213388Z","iopub.status.idle":"2025-04-22T11:48:00.228721Z","shell.execute_reply.started":"2025-04-22T11:48:00.213360Z","shell.execute_reply":"2025-04-22T11:48:00.227429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Categorical features - special handling\nRef : https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices","metadata":{}},{"cell_type":"code","source":"# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \n                \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \n                \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\",\n                \"Fence\", \"Electrical\"]\n\n\n# The ordinal (ordered) categorical features \nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(1, 11))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"IR3\", \"IR2\", \"IR1\", \"Reg\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"ELO\", \"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"]\n}\n\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\nordered_levels.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.230014Z","iopub.execute_input":"2025-04-22T11:48:00.230332Z","iopub.status.idle":"2025-04-22T11:48:00.258330Z","shell.execute_reply.started":"2025-04-22T11:48:00.230307Z","shell.execute_reply":"2025-04-22T11:48:00.257118Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Append features","metadata":{}},{"cell_type":"code","source":"ms_subclass_mapping = {\n    20: \"1-STORY 1946 & NEWER ALL STYLES\",\n    30: \"1-STORY 1945 & OLDER\",\n    40: \"1-STORY W/FINISHED ATTIC ALL AGES\",\n    45: \"1-1/2 STORY - UNFINISHED ALL AGES\",\n    50: \"1-1/2 STORY FINISHED ALL AGES\",\n    60: \"2-STORY 1946 & NEWER\",\n    70: \"2-STORY 1945 & OLDER\",\n    75: \"2-1/2 STORY ALL AGES\",\n    80: \"SPLIT OR MULTI-LEVEL\",\n    85: \"SPLIT FOYER\",\n    90: \"DUPLEX - ALL STYLES AND AGES\",\n    120: \"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\",\n    150: \"1-1/2 STORY PUD - ALL AGES\",\n    160: \"2-STORY PUD - 1946 & NEWER\",\n    180: \"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\",\n    190: \"2 FAMILY CONVERSION - ALL STYLES AND AGES\"\n}\n\nms_class_mapping = {\n    \"1-STORY 1946 & NEWER ALL STYLES\": \"1-Story\",\n    \"1-STORY 1945 & OLDER\": \"1-Story\",\n    \"1-STORY W/FINISHED ATTIC ALL AGES\": \"1-Story\",\n    \"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\": \"1-Story\",\n    \"1-1/2 STORY - UNFINISHED ALL AGES\": \"1-1/2 Story\",\n    \"1-1/2 STORY FINISHED ALL AGES\": \"1-1/2 Story\",\n    \"1-1/2 STORY PUD - ALL AGES\": \"1-1/2 Story\",\n    \"2-STORY 1946 & NEWER\": \"2-Story\",\n    \"2-STORY 1945 & OLDER\": \"2-Story\",\n    \"2-STORY PUD - 1946 & NEWER\": \"2-Story\",\n    \"SPLIT OR MULTI-LEVEL\": \"Split-Level\",\n    \"SPLIT FOYER\": \"Split-Level\",\n    \"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\": \"Split-Level\",\n    \"DUPLEX - ALL STYLES AND AGES\": \"Multi-Family/Duplex\",\n    \"2 FAMILY CONVERSION - ALL STYLES AND AGES\": \"Multi-Family/Duplex\",\n    \"2-1/2 STORY ALL AGES\": \"2-1/2 Story\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.259456Z","iopub.execute_input":"2025-04-22T11:48:00.259732Z","iopub.status.idle":"2025-04-22T11:48:00.282323Z","shell.execute_reply.started":"2025-04-22T11:48:00.259709Z","shell.execute_reply":"2025-04-22T11:48:00.280936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def append_features(df):\n    df = df.copy()\n\n    #The commented features below ended up decreasing the overall score\n    \n    df[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    # df[\"Spaciousness\"] = (df['1stFlrSF'] + df['2ndFlrSF']) / df.TotRmsAbvGrd\n    # df[\"Spaciousness\"] = df.GrLivArea / df.TotRmsAbvGrd\n    df[\"Spaciousness\"] = df.GrLivArea / (df.TotRmsAbvGrd + df.FullBath + df.HalfBath + df.KitchenAbvGr)\n\n    # df[\"Age\"] = df.YrSold - df.YearBuilt\n    # df[\"Age_since_mod\"] = df.YrSold - df.YearRemodAdd\n    # print(df.Age_since_mod.describe())\n\n    # bldg_dummies = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    # df = df.join(bldg_dummies.mul(df.GrLivArea, axis=0))\n    \n    # df[\"PorchTypes\"] = df[[\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\"]].gt(0.0).sum(axis=1)\n\n    # df[\"TotalOutsideSF\"] = df.WoodDeckSF + df.OpenPorchSF + df.EnclosedPorch + df[\"3SsnPorch\"] + df.ScreenPorch\n\n    df[\"MSClass\"] = (df[\"MSSubClass\"].map(ms_subclass_mapping)\n                                    .map(ms_class_mapping)\n                                    .astype('category')\n                                    .cat.add_categories(\"None\")\n                                    .fillna(\"None\"))\n    df[\"IsPUD\"] = (df[\"MSSubClass\"].map(ms_subclass_mapping)\n                                  .str.contains('PUD')\n                                  .astype('category')\n                                  .cat.add_categories(\"None\")\n                                  .fillna(\"None\"))\n    # df.drop(columns = \"MSSubClass\", inplace = True)\n\n    # df[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n\n    # #PCA inspired as specified in https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices\n    # df[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    # df[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n\n    # df[\"OverallScore\"] = df.OverallQual.cat.codes * df.OverallCond.cat.codes\n    # df[\"OverallScore\"] = df.OverallQual.cat.codes + df.OverallCond.cat.codes\n\n    # df[\"LotAreaFrontage\"] = df.LotArea * (df.LotFrontage + 21.0/10)  \n    #                                     # adding a small value to avoid effect of 0 LotFrontage. \n    #                                     # 21 is minimum LotFrontage before replacing NA with 0\n    # df[\"LotAreaFrontage\"] = df.LotArea * df.LotFrontage\n\n    # df[\"Age_with_quality\"] = (df.YrSold - df.YearBuilt) * df.OverallQual.cat.codes \n\n    # df[\"TotalBathrooms\"] = df.FullBath + (0.5 * df.HalfBath) + df.BsmtFullBath + (0.5 * df.BsmtHalfBath)\n\n    df[\"GarageAreaPerCar\"] = df.GarageArea / (df.GarageCars + 0.1)\n    # print(df[\"GarageAreaPerCar\"].describe())\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.283527Z","iopub.execute_input":"2025-04-22T11:48:00.283876Z","iopub.status.idle":"2025-04-22T11:48:00.302764Z","shell.execute_reply.started":"2025-04-22T11:48:00.283835Z","shell.execute_reply":"2025-04-22T11:48:00.301099Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load data and process","metadata":{}},{"cell_type":"code","source":"X, y = load_and_preprocess_data()\nX_test, _ = load_and_preprocess_data(train_data = False)\n\nprint(\"removing less important features\")\nfeatures_to_drop = ['PoolQC', 'MiscVal', 'MoSold', 'PoolArea', 'MiscFeature', 'Utilities']\nX.drop(columns = features_to_drop, inplace = True)\nX_test.drop(columns = features_to_drop, inplace = True)\nprint(X.shape)\nprint(X_test.shape)\n\nprint(\"appending features\")\nX = append_features(X)\nprint(X.shape)\nX_test = append_features(X_test)\nprint(X_test.shape)\n\ndef remove_columns_from_list(orig_list, to_remove):\n    return [f for f in orig_list if f not in to_remove]\n    \nordinal_categorical_cols = remove_columns_from_list(ordered_levels.keys(), features_to_drop)\nfeatures_nom = remove_columns_from_list(features_nom, features_to_drop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.306737Z","iopub.execute_input":"2025-04-22T11:48:00.307294Z","iopub.status.idle":"2025-04-22T11:48:00.575557Z","shell.execute_reply.started":"2025-04-22T11:48:00.307241Z","shell.execute_reply":"2025-04-22T11:48:00.574384Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Append Cluster information as training features","metadata":{}},{"cell_type":"code","source":"class AppendKMeans(BaseEstimator, TransformerMixin):\n    def __init__(self, cluster_columns, n_clusters=20, return_cluster=True, return_distances=False):\n        self.cluster_columns = cluster_columns\n        self.n_clusters = n_clusters\n        self.return_cluster = return_cluster\n        self.return_distances = return_distances\n\n    def fit(self, X, y=None):\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        self.scaler = StandardScaler()\n        X_scaled = self.scaler.fit_transform(X[self.cluster_columns])  # Scale features\n        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=SEED)\n        self.kmeans.fit(X_scaled)  # Fit K-Means on scaled features\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        X_scaled = self.scaler.transform(X[self.cluster_columns])  # Apply same scaling as training\n        if self.return_cluster:\n            result[\"Cluster\"] = self.kmeans.predict(X_scaled)  # Get cluster\n        if self.return_distances:\n            cluster_distances = self.kmeans.transform(X_scaled)\n            cluster_distances = pd.DataFrame(\n                    cluster_distances, columns=[f\"distance_centroid_{i}\" for i in range(cluster_distances.shape[1])]\n            )\n            cluster_distances.set_index(X.index, inplace = True)\n            result = result.join(cluster_distances)\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.577393Z","iopub.execute_input":"2025-04-22T11:48:00.577770Z","iopub.status.idle":"2025-04-22T11:48:00.586700Z","shell.execute_reply.started":"2025-04-22T11:48:00.577739Z","shell.execute_reply":"2025-04-22T11:48:00.585583Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Append PCA","metadata":{}},{"cell_type":"code","source":"class AppendPCA(BaseEstimator, TransformerMixin):\n    def __init__(self, pca_columns, n_components=2, pca_col_prefix=\"PCA\"):\n        self.pca_columns = pca_columns\n        self.n_components = n_components\n        self.pca_col_prefix = pca_col_prefix\n\n    def fit(self, X, y=None):\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        self.scaler = StandardScaler()\n        X_scaled = self.scaler.fit_transform(X[self.pca_columns])  # Scale features\n        self.pca = PCA(n_components=self.n_components, random_state=SEED)\n        self.pca.fit(X_scaled)  # Fit PCA on scaled features\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        X_scaled = self.scaler.transform(X[self.pca_columns])  # Apply same scaling as training\n        pca_components = self.pca.transform(X_scaled)  # Apply PCA\n        # print(self.pca.explained_variance_ratio_)\n        # print(np.cumsum(self.pca.explained_variance_ratio_))\n        pca_components = pd.DataFrame(\n                    pca_components, columns=[f\"{self.pca_col_prefix}_{i}\" for i in range(pca_components.shape[1])]\n        )\n        pca_components.set_index(X.index, inplace = True)\n        result = result.join(pca_components)\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.587756Z","iopub.execute_input":"2025-04-22T11:48:00.588037Z","iopub.status.idle":"2025-04-22T11:48:00.615892Z","shell.execute_reply.started":"2025-04-22T11:48:00.588013Z","shell.execute_reply":"2025-04-22T11:48:00.614501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Target Encoding","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder(BaseEstimator, TransformerMixin):\n    \n    #encoder_other_params should be a dict of argument_name and value\n    # This is done to ensure it works properly within Pipeline\n    # Not passing it as kwargs, because Pipeline uses sklearn.base.clone() and clone does not retain kwargs\n    def __init__(self, cols, encoder, encoder_other_params):\n        self.cols = cols\n        self.encoder = encoder\n        self.cv = KFold(n_splits=5)\n        self.encoder_other_params = encoder_other_params  \n        \n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit(self, X, y):\n        self.fitted_encoders_ = []\n        X_encoded = []\n        for idx_encode, _ in self.cv.split(X):\n            fitted_encoder = self.encoder(cols=self.cols, **self.encoder_other_params)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            self.fitted_encoders_.append(fitted_encoder)\n        return self\n\n    # To transform the data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        #drop columns for which target encoding has been created and join with target encodings\n        return X.drop(columns=self.cols).join(X_encoded)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.617581Z","iopub.execute_input":"2025-04-22T11:48:00.617981Z","iopub.status.idle":"2025-04-22T11:48:00.642635Z","shell.execute_reply.started":"2025-04-22T11:48:00.617945Z","shell.execute_reply":"2025-04-22T11:48:00.641431Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training pipeline","metadata":{}},{"cell_type":"markdown","source":"Lets define a Transformer to convert categorical columns to their codes","metadata":{}},{"cell_type":"code","source":"class OrdinalEncoder(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        for col in result.columns:\n            result[col] = result[col].cat.codes\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.643740Z","iopub.execute_input":"2025-04-22T11:48:00.644045Z","iopub.status.idle":"2025-04-22T11:48:00.664306Z","shell.execute_reply.started":"2025-04-22T11:48:00.644007Z","shell.execute_reply":"2025-04-22T11:48:00.663071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols = [cname for cname in X.columns if\n                    X[cname].dtype == \"category\"]\n\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\nsmall_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() < 10 and cname not in ordinal_categorical_cols]\nlarge_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() >= 10 and cname not in ordinal_categorical_cols]\n\nprint(len(ordinal_categorical_cols))\nprint(len(small_cat_categorical_cols))\nprint(len(large_cat_categorical_cols))\nprint(len(categorical_cols))  \nprint(len(numerical_cols))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.665434Z","iopub.execute_input":"2025-04-22T11:48:00.665701Z","iopub.status.idle":"2025-04-22T11:48:00.705055Z","shell.execute_reply.started":"2025-04-22T11:48:00.665679Z","shell.execute_reply":"2025-04-22T11:48:00.703659Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train and test data have same distribution for all of the important variables as seen in the plots in https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2-exploratory\n\nWhile creating train-valid splits, we'll simulate this by binning sale price (i.e. the target variable) and ensuring that train and valid have same proportion of samples from each of these bins.\n\n(I did explore creating a new concatenated column of OverallQual, Neighborhood, binned GarageArea, binned GrLivArea, binned YearBuilt, binned YearRemodAdd, binned YrSold. But the concatenated column had a large number of unique values with only 1 occurence, which caused issues during train-valid split based on this column. This issue persisted even after decreasing bin size, using fewer columns to obtain the concatenated column. So decided to bin sale price for train-valid split.) ","metadata":{}},{"cell_type":"code","source":"strat_y = pd.qcut(np.log(y), q=20, labels=False)\nstrat_y.value_counts().sort_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.706587Z","iopub.execute_input":"2025-04-22T11:48:00.706962Z","iopub.status.idle":"2025-04-22T11:48:00.725230Z","shell.execute_reply.started":"2025-04-22T11:48:00.706935Z","shell.execute_reply":"2025-04-22T11:48:00.723988Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scoring function","metadata":{}},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor()):\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    \n    log_y = np.log(y)\n    strat_y = pd.qcut(log_y, q=20, labels=False)\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n    splits = list(skf.split(X, strat_y))\n    \n    score = cross_val_score(\n        model, X, log_y, cv=splits, scoring=\"neg_root_mean_squared_error\"\n    )\n\n    # score = cross_val_score(\n    #     model, X, log_y, cv=5, scoring=\"neg_root_mean_squared_error\"\n    # )    \n    \n    print(score)\n    print(-1*np.median(score))\n    print(np.std(score))\n    score = -1 * np.mean(score)\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.726573Z","iopub.execute_input":"2025-04-22T11:48:00.727015Z","iopub.status.idle":"2025-04-22T11:48:00.744251Z","shell.execute_reply.started":"2025-04-22T11:48:00.726985Z","shell.execute_reply":"2025-04-22T11:48:00.742842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pipeline definitions","metadata":{}},{"cell_type":"code","source":"#Pipeline 1\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('small_cat_catcode', OrdinalEncoder())\n])\n\npipeline_xgb1 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])\n# score_dataset(X, y, pipeline_xgb1)\n# [-0.12785618 -0.13046663 -0.14520162 -0.17736176 -0.11825496]\n# 0.13046663079150023\n# 0.02065921056003522\n# 0.13982822954073137","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.745413Z","iopub.execute_input":"2025-04-22T11:48:00.745738Z","iopub.status.idle":"2025-04-22T11:48:00.765982Z","shell.execute_reply.started":"2025-04-22T11:48:00.745711Z","shell.execute_reply":"2025-04-22T11:48:00.764749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 2\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder()),\n    ('scaler', StandardScaler())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_xgb2 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_cols+[col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.767312Z","iopub.execute_input":"2025-04-22T11:48:00.767653Z","iopub.status.idle":"2025-04-22T11:48:00.796464Z","shell.execute_reply.started":"2025-04-22T11:48:00.767622Z","shell.execute_reply":"2025-04-22T11:48:00.794976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 3\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder()),\n    ('scaler', StandardScaler())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_xgb3 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=True)),\n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, (numerical_cols + \n                                           [col + \"_encoded\" for col in large_cat_categorical_cols] + \n                                           [f\"PCA_{i}\" for i in range(5)] + \n                                           [f\"distance_centroid_{i}\" for i in range(10)])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols+['Cluster'])\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.797785Z","iopub.execute_input":"2025-04-22T11:48:00.798074Z","iopub.status.idle":"2025-04-22T11:48:00.824364Z","shell.execute_reply.started":"2025-04-22T11:48:00.798047Z","shell.execute_reply":"2025-04-22T11:48:00.822911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Pipeline 4 - RandomForestRegressor\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('small_cat_catcode', OrdinalEncoder())\n])\n\npipeline_rf = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', RandomForestRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.825639Z","iopub.execute_input":"2025-04-22T11:48:00.826121Z","iopub.status.idle":"2025-04-22T11:48:00.851236Z","shell.execute_reply.started":"2025-04-22T11:48:00.826081Z","shell.execute_reply":"2025-04-22T11:48:00.849856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 5\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_xgb5 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.852419Z","iopub.execute_input":"2025-04-22T11:48:00.852776Z","iopub.status.idle":"2025-04-22T11:48:00.879643Z","shell.execute_reply.started":"2025-04-22T11:48:00.852746Z","shell.execute_reply":"2025-04-22T11:48:00.878232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 6\nnumerical_transformer = Pipeline(steps=[\n    ('skew_handler', PowerTransformer(method='yeo-johnson', standardize=False)),\n    ('scaler', RobustScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder()),\n    ('scaler', RobustScaler())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_xgb6 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_cols+[col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.880796Z","iopub.execute_input":"2025-04-22T11:48:00.881054Z","iopub.status.idle":"2025-04-22T11:48:00.907914Z","shell.execute_reply.started":"2025-04-22T11:48:00.881032Z","shell.execute_reply":"2025-04-22T11:48:00.906533Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 7 - only k-means\n\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_xgb7 = Pipeline([\n    ('append_kmeans', AppendKMeans(X.columns, \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=False)),\n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, ([col + \"_encoded\" for col in large_cat_categorical_cols])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.909094Z","iopub.execute_input":"2025-04-22T11:48:00.909466Z","iopub.status.idle":"2025-04-22T11:48:00.937154Z","shell.execute_reply.started":"2025-04-22T11:48:00.909433Z","shell.execute_reply":"2025-04-22T11:48:00.935738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 8 - only 1-hot encode for XGBRegressor\n\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('smallcat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('largecat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_xgb8 = Pipeline([ \n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols),\n            ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.944359Z","iopub.execute_input":"2025-04-22T11:48:00.944678Z","iopub.status.idle":"2025-04-22T11:48:00.961426Z","shell.execute_reply.started":"2025-04-22T11:48:00.944653Z","shell.execute_reply":"2025-04-22T11:48:00.959796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 9\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('largecat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_xgb9 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=True)),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, (numerical_cols + \n                                           [f\"PCA_{i}\" for i in range(5)] + \n                                           [f\"distance_centroid_{i}\" for i in range(10)])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols+['Cluster']),\n            ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor(random_state = SEED))         \n])\n\n# score_dataset(X, y, pipeline_xgb9)\n# [-0.13190184 -0.1366358  -0.14314017 -0.17554378 -0.12275222]\n# 0.13663580215769133\n# 0.01804277868680093\n# 0.1419947618503093","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.964492Z","iopub.execute_input":"2025-04-22T11:48:00.964805Z","iopub.status.idle":"2025-04-22T11:48:00.980658Z","shell.execute_reply.started":"2025-04-22T11:48:00.964780Z","shell.execute_reply":"2025-04-22T11:48:00.979453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 10\npipeline_xgb10 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=False, return_distances=True)),\n    ('model', XGBRegressor(random_state = SEED, enable_categorical = True))         \n])\n\n# score_dataset(X, y, pipeline_xgb10)\n# [-0.13683021 -0.12144668 -0.14358679 -0.17946046 -0.12809528]\n# 0.13683021145563887\n# 0.02023977746270551\n# 0.14188388439875155","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:00.981540Z","iopub.execute_input":"2025-04-22T11:48:00.981800Z","iopub.status.idle":"2025-04-22T11:48:01.005790Z","shell.execute_reply.started":"2025-04-22T11:48:00.981777Z","shell.execute_reply":"2025-04-22T11:48:01.004453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline CatBoost 1\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('small_cat_catcode', OrdinalEncoder())\n])\n\npipeline_cb1 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', CatBoostRegressor(random_state = SEED, verbose = False))         \n])\n# score_dataset(X, y, pipeline_cb1)\n# [-0.11624901 -0.11453878 -0.12176986 -0.1552284  -0.10681426]\n# 0.11624900798690328\n# 0.016848130288228083\n# 0.1229200608367171","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.007140Z","iopub.execute_input":"2025-04-22T11:48:01.007543Z","iopub.status.idle":"2025-04-22T11:48:01.037412Z","shell.execute_reply.started":"2025-04-22T11:48:01.007500Z","shell.execute_reply":"2025-04-22T11:48:01.035933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline CatBoost 2 - catboost of Pipeline 5\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_cb2 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', CatBoostRegressor(random_state = SEED, verbose = False))         \n])\n\n\n# score_dataset(X, y, pipeline_cb2)\n# [-0.11657571 -0.11399993 -0.12022822 -0.151068   -0.10718364]\n# 0.11657570939426244\n# 0.015237178152076106\n# 0.12181110094841437","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.038480Z","iopub.execute_input":"2025-04-22T11:48:01.038800Z","iopub.status.idle":"2025-04-22T11:48:01.056227Z","shell.execute_reply.started":"2025-04-22T11:48:01.038774Z","shell.execute_reply":"2025-04-22T11:48:01.055104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline Catboost 3 - CatBoost of k-means only pipeline\n\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_cb3 = Pipeline([\n    ('append_kmeans', AppendKMeans(X.columns, \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=False)),\n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, ([col + \"_encoded\" for col in large_cat_categorical_cols])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', CatBoostRegressor(random_state = SEED, verbose = False))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.057770Z","iopub.execute_input":"2025-04-22T11:48:01.058200Z","iopub.status.idle":"2025-04-22T11:48:01.086445Z","shell.execute_reply.started":"2025-04-22T11:48:01.058140Z","shell.execute_reply":"2025-04-22T11:48:01.085087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline Catboost 4\n\npipeline_cb4 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('model', CatBoostRegressor(random_state = SEED, verbose = False, cat_features = categorical_cols))         \n])\n\n#score_dataset(X, y, pipeline_cb4)\n# [-0.1245166  -0.12251158 -0.12408372 -0.15749913 -0.11058973]\n# 0.124083723980751\n# 0.015689374060298498\n# 0.12784015103401533","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.087660Z","iopub.execute_input":"2025-04-22T11:48:01.088014Z","iopub.status.idle":"2025-04-22T11:48:01.109131Z","shell.execute_reply.started":"2025-04-22T11:48:01.087979Z","shell.execute_reply":"2025-04-22T11:48:01.107863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline CatBoost 5\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('smallcat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('largecat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_cb5 = Pipeline([ \n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols),\n            ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', CatBoostRegressor(random_state = SEED, verbose = False))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.110310Z","iopub.execute_input":"2025-04-22T11:48:01.110617Z","iopub.status.idle":"2025-04-22T11:48:01.136292Z","shell.execute_reply.started":"2025-04-22T11:48:01.110591Z","shell.execute_reply":"2025-04-22T11:48:01.134868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline Catboost 6\n\npipeline_cb6 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=False, return_distances=True)),\n    ('model', CatBoostRegressor(random_state = SEED, verbose = False, cat_features = categorical_cols))         \n])\n#score_dataset(X, y, pipeline_cb6)\n# [-0.12623897 -0.12059074 -0.12858833 -0.15933993 -0.11112165]\n# 0.1262389656010505\n# 0.0162388462195836\n# 0.12917592388929722","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.137432Z","iopub.execute_input":"2025-04-22T11:48:01.137704Z","iopub.status.idle":"2025-04-22T11:48:01.162886Z","shell.execute_reply.started":"2025-04-22T11:48:01.137680Z","shell.execute_reply":"2025-04-22T11:48:01.161614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 1\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('small_cat_catcode', OrdinalEncoder())\n])\n\npipeline_lgbm1 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])\n# score_dataset(X, y, pipeline_lgbm1)\n# [-0.12668316 -0.1288637  -0.13902374 -0.16449322 -0.11501904]\n# 0.12886369701337194\n# 0.016684932158762624\n# 0.1348165713973164","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.164215Z","iopub.execute_input":"2025-04-22T11:48:01.164593Z","iopub.status.idle":"2025-04-22T11:48:01.189529Z","shell.execute_reply.started":"2025-04-22T11:48:01.164557Z","shell.execute_reply":"2025-04-22T11:48:01.188300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 2\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_lgbm2 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])\n# score_dataset(X, y, pipeline_lgbm2)\n# [-0.12638687 -0.13201789 -0.13919122 -0.16584972 -0.11779284]\n# 0.1320178902768938\n# 0.016374693948860188\n# 0.13624770822490476","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.190364Z","iopub.execute_input":"2025-04-22T11:48:01.190659Z","iopub.status.idle":"2025-04-22T11:48:01.203522Z","shell.execute_reply.started":"2025-04-22T11:48:01.190634Z","shell.execute_reply":"2025-04-22T11:48:01.202256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 3\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder()),\n    ('scaler', StandardScaler())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_lgbm3 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=True)),\n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, (numerical_cols + \n                                           [col + \"_encoded\" for col in large_cat_categorical_cols] + \n                                           [f\"PCA_{i}\" for i in range(5)] + \n                                           [f\"distance_centroid_{i}\" for i in range(10)])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols+['Cluster'])\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.204624Z","iopub.execute_input":"2025-04-22T11:48:01.204886Z","iopub.status.idle":"2025-04-22T11:48:01.231674Z","shell.execute_reply.started":"2025-04-22T11:48:01.204863Z","shell.execute_reply":"2025-04-22T11:48:01.230322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 4 - kmeans only\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_lgbm4 = Pipeline([\n    ('append_kmeans', AppendKMeans(X.columns, \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=False)),\n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, ([col + \"_encoded\" for col in large_cat_categorical_cols])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.232721Z","iopub.execute_input":"2025-04-22T11:48:01.232992Z","iopub.status.idle":"2025-04-22T11:48:01.250996Z","shell.execute_reply.started":"2025-04-22T11:48:01.232970Z","shell.execute_reply":"2025-04-22T11:48:01.249665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 5 - only 1-hot encoding\n\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('smallcat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('largecat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\npipeline_lgbm5 = Pipeline([ \n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols),\n            ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.252221Z","iopub.execute_input":"2025-04-22T11:48:01.252488Z","iopub.status.idle":"2025-04-22T11:48:01.278016Z","shell.execute_reply.started":"2025-04-22T11:48:01.252467Z","shell.execute_reply":"2025-04-22T11:48:01.276381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 6 \nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nlarge_categorical_transformer = Pipeline(steps=[\n    ('largecat_onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\npipeline_lgbm6 = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)), \n    ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n                                   n_clusters = 10,\n                                   return_cluster=True, return_distances=True)),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, (numerical_cols + \n                                           [f\"PCA_{i}\" for i in range(5)] + \n                                           [f\"distance_centroid_{i}\" for i in range(10)])\n            ),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols+['Cluster']),\n            ('large_cat', large_categorical_transformer, large_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1))         \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.279423Z","iopub.execute_input":"2025-04-22T11:48:01.279818Z","iopub.status.idle":"2025-04-22T11:48:01.303570Z","shell.execute_reply.started":"2025-04-22T11:48:01.279779Z","shell.execute_reply":"2025-04-22T11:48:01.302250Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimize hyperparameters","metadata":{}},{"cell_type":"markdown","source":"* This section contains functions to optimize the pipeline hyperparameters using Optuna\n* To run the code in this section, rename any of the pipelines defined in the previous section to 'pipeline' and uncomment the corresponding objective function in this section","metadata":{}},{"cell_type":"code","source":"# def xgb_objective(trial):  \n    \n#     params = {\n#         'model__n_estimators':       trial.suggest_int('model__n_estimators', 500, 2000, step = 50),\n#         'model__learning_rate':      trial.suggest_float('model__learning_rate', 1e-4, 0.1, log=True),\n#         'model__max_depth':          trial.suggest_int('model__max_depth', 0, 16),\n#         'model__min_child_weight':   trial.suggest_int('model__min_child_weight', 1, 10),\n#         'model__lambda':             trial.suggest_float('model__lambda', 1e-4, 10.0, log = True),\n#         'model__alpha':              trial.suggest_float('model__alpha', 1e-4, 10.0, log = True),\n#         'model__subsample':          trial.suggest_float('model__subsample', 0.4, 1.0, step = 0.01),\n#         'model__colsample_bytree':   trial.suggest_float('model__colsample_bytree', 0.4, 1.0, step = 0.01)\n#     }\n#     pipeline_clone = clone(pipeline)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(xgb_objective, n_trials = 300)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"XGB tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.457364Z","iopub.execute_input":"2025-04-22T11:48:01.457775Z","iopub.status.idle":"2025-04-22T11:48:01.480875Z","shell.execute_reply.started":"2025-04-22T11:48:01.457730Z","shell.execute_reply":"2025-04-22T11:48:01.479665Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #defining a separate objective function with additional params for categorical data handling\n\n# def xgb10_objective(trial):  \n    \n#     params = {\n#         'model__n_estimators':       trial.suggest_int('model__n_estimators', 500, 2000, step = 50),\n#         'model__learning_rate':      trial.suggest_float('model__learning_rate', 1e-4, 0.1, log=True),\n#         'model__max_depth':          trial.suggest_int('model__max_depth', 0, 16),\n#         'model__min_child_weight':   trial.suggest_int('model__min_child_weight', 1, 10),\n#         'model__lambda':             trial.suggest_float('model__lambda', 1e-4, 10.0, log = True),\n#         'model__alpha':              trial.suggest_float('model__alpha', 1e-4, 10.0, log = True),\n#         'model__subsample':          trial.suggest_float('model__subsample', 0.4, 1.0, step = 0.01),\n#         'model__colsample_bytree':   trial.suggest_float('model__colsample_bytree', 0.4, 1.0, step = 0.01),\n#         'model__max_cat_to_onehot':  trial.suggest_int('model__max_cat_to_onehot', 2, 25),\n#         'model__max_cat_threshold':  trial.suggest_int('model__max_cat_threshold', 2, 32),\n\n#     }\n#     pipeline_clone = clone(pipeline_xgb10)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(xgb10_objective, n_trials = 300)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"XGB10 tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.482076Z","iopub.execute_input":"2025-04-22T11:48:01.482510Z","iopub.status.idle":"2025-04-22T11:48:01.503379Z","shell.execute_reply.started":"2025-04-22T11:48:01.482460Z","shell.execute_reply":"2025-04-22T11:48:01.502007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def rf_objective(trial):  \n    \n#     params = {\n#         'model__n_estimators':          trial.suggest_int('model__n_estimators', 500, 10000, step = 100),\n#         'model__max_depth':             trial.suggest_categorical('model__max_depth', [None] + list(range(4, 9))),\n#         'model__min_samples_split':     trial.suggest_int('model__min_samples_split', 2, 20),\n#         'model__min_samples_leaf':      trial.suggest_int('model__min_samples_leaf', 1, 20),\n#         'model__max_features':          trial.suggest_categorical('model__max_features', [\"sqrt\", \"log2\", None]),\n#         'model__min_impurity_decrease': trial.suggest_categorical('model__min_impurity_decrease',\n#                                                                   [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n#     }\n#     pipeline_clone = clone(pipeline)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(rf_objective, n_trials = 100)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"RF tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.504689Z","iopub.execute_input":"2025-04-22T11:48:01.505004Z","iopub.status.idle":"2025-04-22T11:48:01.527657Z","shell.execute_reply.started":"2025-04-22T11:48:01.504977Z","shell.execute_reply":"2025-04-22T11:48:01.526190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def cb_objective(trial):  \n    \n#     params = {\n#         'model__n_estimators':       trial.suggest_int('model__n_estimators', 500, 2000, step = 50),\n#         'model__learning_rate':      trial.suggest_float('model__learning_rate', 1e-4, 0.1, log=True),\n#         'model__l2_leaf_reg':        trial.suggest_float('model__l2_leaf_reg', 1e-3, 10.0, log = True),\n#         'model__min_data_in_leaf':   trial.suggest_int('model__min_data_in_leaf', 1, 50),\n#         'model__max_depth':          trial.suggest_int('model__max_depth', 4, 16),\n#         'model__subsample':          trial.suggest_float('model__subsample', 0.4, 1.0, step = 0.01),\n#         'model__colsample_bylevel':  trial.suggest_float('model__colsample_bylevel', 0.4, 1.0, step = 0.01)\n#     }\n\n#     pipeline_clone = clone(pipeline)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(cb_objective, n_trials = 50)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"CB tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.529109Z","iopub.execute_input":"2025-04-22T11:48:01.529670Z","iopub.status.idle":"2025-04-22T11:48:01.555271Z","shell.execute_reply.started":"2025-04-22T11:48:01.529633Z","shell.execute_reply":"2025-04-22T11:48:01.553798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def lgbm_objective(trial):  \n    \n#     params = {\n#          'model__n_estimators':       trial.suggest_int('model__n_estimators', 100, 2000, step = 50),\n#          'model__learning_rate':      trial.suggest_float('model__learning_rate', 1e-4, 0.1, log=True),\n#          'model__num_leaves':         trial.suggest_int('model__num_leaves', 16, 256),\n#          'model__max_depth':          trial.suggest_int('model__max_depth', 0, 16),\n#          'model__min_data_in_leaf':   trial.suggest_int('model__min_data_in_leaf', 1, 50),\n#          'model__bagging_freq':       trial.suggest_int('model__bagging_freq', 0, 7),\n#          'model__bagging_fraction':   trial.suggest_float('model__bagging_fraction', 0.5, 1.0, step = 0.05),\n#          'model__reg_alpha':          trial.suggest_float('model__reg_alpha', 1e-4, 10.0, log = True),\n#          'model__reg_lambda':         trial.suggest_float('model__reg_lambda', 1e-4, 10.0, log = True),\n#          'model__colsample_bytree':   trial.suggest_float('model__colsample_bytree', 0.4, 1.0, step = 0.01)\n#     }\n\n#     pipeline_clone = clone(pipeline)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(lgbm_objective, n_trials = 300)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"LGBM tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.556656Z","iopub.execute_input":"2025-04-22T11:48:01.557032Z","iopub.status.idle":"2025-04-22T11:48:01.581563Z","shell.execute_reply.started":"2025-04-22T11:48:01.556997Z","shell.execute_reply":"2025-04-22T11:48:01.580312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with pipeline1\nbest_params_xgb1 = {'model__n_estimators': 1850, 'model__learning_rate': 0.0164692960710159, \n                    'model__max_depth': 4, 'model__min_child_weight': 2, \n                    'model__lambda': 0.00030967125261382463, 'model__alpha': 0.009462027221582257, \n                    'model__subsample': 0.64, 'model__colsample_bytree': 0.46}\n# Best is trial 212 with value: 0.12096327119801184.\n# [-0.11749978 -0.11468448 -0.11998631 -0.16015004 -0.09249576]\n# 0.1174997758651165\n# 0.02190148844115302","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.654712Z","iopub.execute_input":"2025-04-22T11:48:01.655301Z","iopub.status.idle":"2025-04-22T11:48:01.671898Z","shell.execute_reply.started":"2025-04-22T11:48:01.655262Z","shell.execute_reply":"2025-04-22T11:48:01.670818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with pipeline2\nbest_params_xgb2 ={'model__n_estimators': 1850, 'model__learning_rate': 0.007663483674441529, \n                   'model__max_depth': 4, 'model__min_child_weight': 1, \n                   'model__lambda': 1.3221982712197484, 'model__alpha': 0.0005031631526708031, \n                   'model__subsample': 0.66, 'model__colsample_bytree': 0.5900000000000001}\n# Best is trial 169 with value: 0.12121695838464552.\n# [-0.1190666  -0.11047241 -0.12027858 -0.15368264 -0.10258457]\n# 0.11906659648415295\n# 0.0174478434513716","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.699075Z","iopub.execute_input":"2025-04-22T11:48:01.699504Z","iopub.status.idle":"2025-04-22T11:48:01.723863Z","shell.execute_reply.started":"2025-04-22T11:48:01.699468Z","shell.execute_reply":"2025-04-22T11:48:01.722486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with pipeline3\nbest_params_xgb3 = {'model__n_estimators': 1350, 'model__learning_rate': 0.019180364463132607, \n                    'model__max_depth': 3, 'model__min_child_weight': 1, \n                    'model__lambda': 0.380879553148292, 'model__alpha': 0.1694031754175522, \n                    'model__subsample': 0.52, 'model__colsample_bytree': 0.8300000000000001}\n# Best is trial 255 with value: 0.12291040055737397.\n# [-0.1207175  -0.11784717 -0.12084213 -0.15751711 -0.09762809]\n# 0.12071750059786712\n# 0.01934705328976381","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.725320Z","iopub.execute_input":"2025-04-22T11:48:01.725848Z","iopub.status.idle":"2025-04-22T11:48:01.748570Z","shell.execute_reply.started":"2025-04-22T11:48:01.725800Z","shell.execute_reply":"2025-04-22T11:48:01.747479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Pipeline 4 best params\nbest_params_rf = {'model__n_estimators': 8100, 'model__max_depth': None, \n                  'model__min_samples_split': 2, 'model__min_samples_leaf': 1, \n                  'model__max_features': 'log2', 'model__min_impurity_decrease': 1e-06}\n# Best is trial 99 with value: 0.13801475483285586.\n# [-0.1305587  -0.12929222 -0.14595504 -0.15818268 -0.12608512]\n# 0.13055870069685813\n# 0.0121965965512414","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.749815Z","iopub.execute_input":"2025-04-22T11:48:01.750120Z","iopub.status.idle":"2025-04-22T11:48:01.775300Z","shell.execute_reply.started":"2025-04-22T11:48:01.750093Z","shell.execute_reply":"2025-04-22T11:48:01.773710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 5 best params\nbest_params_xgb5 = {'model__n_estimators': 1700, 'model__learning_rate': 0.016890178924066624,\n                    'model__max_depth': 3, 'model__min_child_weight': 2,\n                    'model__lambda': 0.006476272438913827, 'model__alpha': 0.00020362981148242182,\n                    'model__subsample': 0.55, 'model__colsample_bytree': 0.62}\n\n# Best is trial 251 with value: 0.12121663671265123.\n# [-0.1183398  -0.11764894 -0.11819146 -0.15724026 -0.09466274]\n# 0.11819145566235034\n# 0.02016416246342805","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.776752Z","iopub.execute_input":"2025-04-22T11:48:01.777202Z","iopub.status.idle":"2025-04-22T11:48:01.801546Z","shell.execute_reply.started":"2025-04-22T11:48:01.777134Z","shell.execute_reply":"2025-04-22T11:48:01.800318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 6 best params\n# skf split - no run is successful, all fail. Default 5 fold CV split does give result","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.802987Z","iopub.execute_input":"2025-04-22T11:48:01.803369Z","iopub.status.idle":"2025-04-22T11:48:01.826483Z","shell.execute_reply.started":"2025-04-22T11:48:01.803316Z","shell.execute_reply":"2025-04-22T11:48:01.825214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 7 best params\nbest_params_xgb7 = {'model__n_estimators': 900, 'model__learning_rate': 0.034132716349379644, \n                    'model__max_depth': 4, 'model__min_child_weight': 3, \n                    'model__lambda': 0.07598434952799418, 'model__alpha': 0.006227713546260122, \n                    'model__subsample': 0.62, 'model__colsample_bytree': 0.42000000000000004}\n# Best is trial 290 with value: 0.12016913498104102.\n# [-0.1231054  -0.10620493 -0.11861282 -0.15727291 -0.09564962]\n# 0.11861282156685948\n# 0.020899470502765815","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.827552Z","iopub.execute_input":"2025-04-22T11:48:01.827825Z","iopub.status.idle":"2025-04-22T11:48:01.852149Z","shell.execute_reply.started":"2025-04-22T11:48:01.827803Z","shell.execute_reply":"2025-04-22T11:48:01.850719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Pipeline 8 best params\nbest_params_xgb8 = {'model__n_estimators': 2000, 'model__learning_rate': 0.013062870439665343, \n                    'model__max_depth': 4, 'model__min_child_weight': 1, \n                    'model__lambda': 0.6898851881426148, 'model__alpha': 0.01942788510854367, \n                    'model__subsample': 0.45, 'model__colsample_bytree': 0.66}\n# Best is trial 238 with value: 0.12218887615283583.\n# [-0.12311578 -0.10393904 -0.11978129 -0.16208063 -0.10202764]\n# 0.11978128899996028\n# 0.021621929170878792","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.853402Z","iopub.execute_input":"2025-04-22T11:48:01.853794Z","iopub.status.idle":"2025-04-22T11:48:01.877872Z","shell.execute_reply.started":"2025-04-22T11:48:01.853755Z","shell.execute_reply":"2025-04-22T11:48:01.876759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 9 best params\nbest_params_xgb9 = {'model__n_estimators': 1300, 'model__learning_rate': 0.017812751084206546, \n                    'model__max_depth': 4, 'model__min_child_weight': 1, \n                    'model__lambda': 0.5374808280674902, 'model__alpha': 0.014717951591959225, \n                    'model__subsample': 0.42000000000000004, 'model__colsample_bytree': 0.5800000000000001}\n\n# Best is trial 262 with value: 0.12289801572950965.\n# [-0.11956882 -0.11307731 -0.12082082 -0.16199867 -0.09902446]\n# 0.1195688216223085\n# 0.02102690141132909","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.878885Z","iopub.execute_input":"2025-04-22T11:48:01.879131Z","iopub.status.idle":"2025-04-22T11:48:01.904501Z","shell.execute_reply.started":"2025-04-22T11:48:01.879108Z","shell.execute_reply":"2025-04-22T11:48:01.903299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline 10 best params\nbest_params_xgb10 = {'model__n_estimators': 1800, 'model__learning_rate': 0.009314521918435957, \n                     'model__max_depth': 4, 'model__min_child_weight': 2, \n                     'model__lambda': 0.05452883626379855, 'model__alpha': 0.0002684304975102518, \n                     'model__subsample': 0.76, 'model__colsample_bytree': 0.46}\n# Best is trial 253 with value: 0.12189723833484438.\n# [-0.11769908 -0.11210582 -0.12542139 -0.15399192 -0.10026798]\n# 0.11769907780421265\n# 0.018021150486328682\n\n#skf split with optuna with cat params\n# best_params_xgb10 = {'model__n_estimators': 950, 'model__learning_rate': 0.024273156624668824, \n#                      'model__max_depth': 4, 'model__min_child_weight': 4, \n#                      'model__lambda': 0.001385577354934915, 'model__alpha': 0.0004628157478762704, \n#                      'model__subsample': 0.78, 'model__colsample_bytree': 0.4, \n#                      'model__max_cat_to_onehot': 5, 'model__max_cat_threshold': 16}\n# # Best is trial 150 with value: 0.1227792632215197.\n# # [-0.11871171 -0.11198431 -0.1244113  -0.15544868 -0.10334032]\n# # 0.11871171137791076\n# # 0.017781468360262627","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.905935Z","iopub.execute_input":"2025-04-22T11:48:01.906251Z","iopub.status.idle":"2025-04-22T11:48:01.929852Z","shell.execute_reply.started":"2025-04-22T11:48:01.906224Z","shell.execute_reply":"2025-04-22T11:48:01.928380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 1\nbest_params_cb1 = {'model__n_estimators': 1600, 'model__learning_rate': 0.013567817011450631, \n                   'model__l2_leaf_reg': 2.352528904227011, 'model__min_data_in_leaf': 33, \n                   'model__max_depth': 7, 'model__subsample': 0.62, \n                   'model__colsample_bylevel': 0.9400000000000001}\n# Best is trial 26 with value: 0.12146870978524071.\n# [-0.11689243 -0.11222937 -0.1195251  -0.1484336  -0.11026306]\n# 0.11689242795517175\n# 0.013876291530023033","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.931199Z","iopub.execute_input":"2025-04-22T11:48:01.931638Z","iopub.status.idle":"2025-04-22T11:48:01.955376Z","shell.execute_reply.started":"2025-04-22T11:48:01.931597Z","shell.execute_reply":"2025-04-22T11:48:01.954147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 2\nbest_params_cb2 = {'model__n_estimators': 1000, 'model__learning_rate': 0.020766651766510266, \n                   'model__l2_leaf_reg': 0.0031728824818652163, 'model__min_data_in_leaf': 50, \n                   'model__max_depth': 6, 'model__subsample': 0.8, \n                   'model__colsample_bylevel': 0.91}\n\n# Best is trial 12 with value: 0.12063624125827858.\n# [-0.1156934  -0.10911198 -0.12282546 -0.15034066 -0.1052097 ]\n# 0.1156933974068409\n# 0.01601476634147856","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.956540Z","iopub.execute_input":"2025-04-22T11:48:01.956839Z","iopub.status.idle":"2025-04-22T11:48:01.979093Z","shell.execute_reply.started":"2025-04-22T11:48:01.956813Z","shell.execute_reply":"2025-04-22T11:48:01.977661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 3\nbest_params_cb3 = {'model__n_estimators': 700, 'model__learning_rate': 0.030625945706803, \n                   'model__l2_leaf_reg': 0.2906471745862896, 'model__min_data_in_leaf': 26, \n                   'model__max_depth': 6, 'model__subsample': 0.66, \n                   'model__colsample_bylevel': 0.64}\n# Best is trial 43 with value: 0.12117629660914572.\n# [-0.11685888 -0.11011589 -0.1235822  -0.1489466  -0.10637792]\n# 0.11685887726354985\n# 0.015079407156906926","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:01.980747Z","iopub.execute_input":"2025-04-22T11:48:01.981215Z","iopub.status.idle":"2025-04-22T11:48:02.000600Z","shell.execute_reply.started":"2025-04-22T11:48:01.981146Z","shell.execute_reply":"2025-04-22T11:48:01.999267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 4\n\nbest_params_cb4_1 = {'model__n_estimators': 1900, 'model__learning_rate': 0.023875793128268784, \n                     'model__l2_leaf_reg': 0.20539579640233013, 'model__min_data_in_leaf': 5, \n                     'model__max_depth': 5, 'model__subsample': 0.9400000000000001, \n                     'model__colsample_bylevel': 0.8500000000000001}\n# # Best is trial 1 with value: 0.12746553160273738\n# # [-0.12479513 -0.11602021 -0.12677251 -0.16181625 -0.10792355]\n# # 0.1247951298785159\n# # 0.01844162469894824\n\nbest_params_cb4_2 = {'model__n_estimators': 1400, 'model__learning_rate': 0.05291628705588727, \n                     'model__l2_leaf_reg': 0.11661179025482198, 'model__min_data_in_leaf': 10, \n                     'model__max_depth': 4, 'model__subsample': 0.99, \n                     'model__colsample_bylevel': 0.67}\n# Best is trial 13 with value: 0.12657391647714436.\n# [-0.12250947 -0.11908302 -0.12198717 -0.16438165 -0.10490827]\n# 0.12198717243937014\n# 0.019962446238785396","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.001703Z","iopub.execute_input":"2025-04-22T11:48:02.002037Z","iopub.status.idle":"2025-04-22T11:48:02.022676Z","shell.execute_reply.started":"2025-04-22T11:48:02.002010Z","shell.execute_reply":"2025-04-22T11:48:02.021365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 5\n\nbest_params_cb5 = {'model__n_estimators': 1850, 'model__learning_rate': 0.03310538371449341, \n                   'model__l2_leaf_reg': 0.5692385591345918, 'model__min_data_in_leaf': 5, \n                   'model__max_depth': 5, 'model__subsample': 0.53, \n                   'model__colsample_bylevel': 0.73}\n# Best is trial 33 with value: 0.12232080734704395.\n# [-0.11730409 -0.10672066 -0.12218277 -0.15967962 -0.1057169 ]\n# 0.11730408572695568\n# 0.019697317031556482","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.023873Z","iopub.execute_input":"2025-04-22T11:48:02.024259Z","iopub.status.idle":"2025-04-22T11:48:02.049129Z","shell.execute_reply.started":"2025-04-22T11:48:02.024215Z","shell.execute_reply":"2025-04-22T11:48:02.047804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost Pipeline 6\n\nbest_params_cb6 = {'model__n_estimators': 1700, 'model__learning_rate': 0.016184394757080008,\n                   'model__l2_leaf_reg': 0.01949463452385371, 'model__min_data_in_leaf': 6,\n                   'model__max_depth': 5, 'model__subsample': 0.5700000000000001,\n                   'model__colsample_bylevel': 0.73}\n# Best is trial 33 with value: 0.1274473054822071\n# [-0.12410766 -0.11949513 -0.12663447 -0.15884384 -0.10815544]\n# 0.124107658094659\n# 0.01692908485762067","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.057261Z","iopub.execute_input":"2025-04-22T11:48:02.057667Z","iopub.status.idle":"2025-04-22T11:48:02.074634Z","shell.execute_reply.started":"2025-04-22T11:48:02.057636Z","shell.execute_reply":"2025-04-22T11:48:02.073284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 1\n\nbest_params_lgbm1 = {'model__n_estimators': 1600, 'model__learning_rate': 0.009731152795312595, \n                     'model__num_leaves': 114, 'model__max_depth': 4, \n                     'model__min_data_in_leaf': 1, 'model__bagging_freq': 7, \n                     'model__bagging_fraction': 0.55, 'model__reg_alpha': 0.1807157822128309, \n                     'model__reg_lambda': 0.09215157159968763, 'model__colsample_bytree': 0.4}\n# Best is trial 243 with value: 0.12052610219793292.\n# [-0.11954391 -0.11328187 -0.11886363 -0.15219455 -0.09874655]\n# 0.11886362989527258\n# 0.01751254964107485","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.076474Z","iopub.execute_input":"2025-04-22T11:48:02.076845Z","iopub.status.idle":"2025-04-22T11:48:02.095939Z","shell.execute_reply.started":"2025-04-22T11:48:02.076809Z","shell.execute_reply":"2025-04-22T11:48:02.094318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 2\n\nbest_params_lgbm2 = {'model__n_estimators': 1050, 'model__learning_rate': 0.014161850233991993, \n                     'model__num_leaves': 203, 'model__max_depth': 5, \n                     'model__min_data_in_leaf': 2, 'model__bagging_freq': 3, \n                     'model__bagging_fraction': 0.65, 'model__reg_alpha': 0.0034654923995791806, \n                     'model__reg_lambda': 0.06528414476899567, 'model__colsample_bytree': 0.43000000000000005}\n# Best is trial 288 with value: 0.12006520251936215.\n# [-0.1175394  -0.10907231 -0.12194504 -0.15602383 -0.09574543]\n# 0.11753940364579261\n# 0.020076009133654676","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.097229Z","iopub.execute_input":"2025-04-22T11:48:02.097692Z","iopub.status.idle":"2025-04-22T11:48:02.121653Z","shell.execute_reply.started":"2025-04-22T11:48:02.097659Z","shell.execute_reply":"2025-04-22T11:48:02.120475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 3 - (with kmeans)\n\nbest_params_lgbm3 = {'model__n_estimators': 1350, 'model__learning_rate': 0.005813900232531856, \n                     'model__num_leaves': 248, 'model__max_depth': 10, \n                     'model__min_data_in_leaf': 20, 'model__bagging_freq': 1, \n                     'model__bagging_fraction': 0.5, 'model__reg_alpha': 0.0028223797745013522, \n                     'model__reg_lambda': 0.005988097246415957, 'model__colsample_bytree': 0.41000000000000003}\n# Best is trial 241 with value: 0.12476945989203363.\n# [-0.12135222 -0.11226465 -0.1272039  -0.1535579  -0.10946863]\n# 0.12135222151106254\n# 0.015728090881840222","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.122975Z","iopub.execute_input":"2025-04-22T11:48:02.123441Z","iopub.status.idle":"2025-04-22T11:48:02.151861Z","shell.execute_reply.started":"2025-04-22T11:48:02.123390Z","shell.execute_reply":"2025-04-22T11:48:02.150317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 4 \n\nbest_params_lgbm4 = {'model__n_estimators': 1600, 'model__learning_rate': 0.016221004562637534, \n                     'model__num_leaves': 55, 'model__max_depth': 4, \n                     'model__min_data_in_leaf': 3, 'model__bagging_freq': 7, \n                     'model__bagging_fraction': 0.7, 'model__reg_alpha': 0.003283241571893786, \n                     'model__reg_lambda': 0.042729411250030144, 'model__colsample_bytree': 0.41000000000000003}\n# Best is trial 233 with value: 0.12056356608490129.\n# [-0.12052822 -0.10662705 -0.12023993 -0.15732043 -0.0981022 ]\n# 0.12023993219991116\n# 0.020248023319354637","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.153460Z","iopub.execute_input":"2025-04-22T11:48:02.153874Z","iopub.status.idle":"2025-04-22T11:48:02.178111Z","shell.execute_reply.started":"2025-04-22T11:48:02.153823Z","shell.execute_reply":"2025-04-22T11:48:02.176834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 5\n\nbest_params_lgbm5 = {'model__n_estimators': 1700, 'model__learning_rate': 0.030862626260224756, \n                     'model__num_leaves': 249, 'model__max_depth': 4, \n                     'model__min_data_in_leaf': 1, 'model__bagging_freq': 1, \n                     'model__bagging_fraction': 0.7, 'model__reg_alpha': 0.00018348579563313004, \n                     'model__reg_lambda': 0.00038494776166918504, 'model__colsample_bytree': 0.61}\n\n# Best is trial 294 with value: 0.12194678876497556.\n# [-0.12324616 -0.10222344 -0.12207349 -0.16217016 -0.1000207 ]\n# 0.1220734899492754\n# 0.02231316891513297","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.179278Z","iopub.execute_input":"2025-04-22T11:48:02.179612Z","iopub.status.idle":"2025-04-22T11:48:02.204824Z","shell.execute_reply.started":"2025-04-22T11:48:02.179584Z","shell.execute_reply":"2025-04-22T11:48:02.203549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline LGBM 6\n\nbest_params_lgbm6 = {'model__n_estimators': 850, 'model__learning_rate': 0.01593545381425983, \n                     'model__num_leaves': 140, 'model__max_depth': 3, \n                     'model__min_data_in_leaf': 2, 'model__bagging_freq': 5, \n                     'model__bagging_fraction': 0.6, 'model__reg_alpha': 0.000599107791544195, \n                     'model__reg_lambda': 0.38106260630011507, 'model__colsample_bytree': 0.81}\n# Best is trial 262 with value: 0.1243739978569125.\n# [-0.12021403 -0.1201359  -0.11912219 -0.16589076 -0.0965071 ]\n# 0.1201359012486722\n# 0.02264091018759263","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.206369Z","iopub.execute_input":"2025-04-22T11:48:02.206819Z","iopub.status.idle":"2025-04-22T11:48:02.228105Z","shell.execute_reply.started":"2025-04-22T11:48:02.206778Z","shell.execute_reply":"2025-04-22T11:48:02.226873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Base model results","metadata":{}},{"cell_type":"markdown","source":"To submit a base model result to the competition, uncomment the cell below and replace \"pipeline\", \"best_params\" to the pipeline/params to be submitted, and also comment out the pipeline definition in the ensemble section(next section).\n\nThe pipeline set with best params will be used to train on full data and obtain test predictions in the last section.\n","metadata":{}},{"cell_type":"code","source":"# pipeline = pipeline_lgbm2\n# best_params = best_params_lgbm2\n# pipeline.set_params(**best_params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#xgb1\n# 0.12096327119801184.\n# [-0.11749978 -0.11468448 -0.11998631 -0.16015004 -0.09249576]\n# 0.1174997758651165\n# 0.02190148844115302\n# public score : 0.12208\n\n#xgb2\n# 0.12121695838464552.\n# [-0.1190666  -0.11047241 -0.12027858 -0.15368264 -0.10258457]\n# 0.11906659648415295\n# 0.0174478434513716\n# public score : 0.12121\n\n#xgb3\n# 0.12291040055737397.\n# [-0.1207175  -0.11784717 -0.12084213 -0.15751711 -0.09762809]\n# 0.12071750059786712\n# 0.01934705328976381\n# public score : 0.12344\n\n#xgb5\n# 0.12121663671265123.\n# [-0.1183398  -0.11764894 -0.11819146 -0.15724026 -0.09466274]\n# 0.11819145566235034\n# 0.02016416246342805\n# public score : 0.12270\n\n#xgb7\n# 0.12016913498104102.\n# [-0.1231054  -0.10620493 -0.11861282 -0.15727291 -0.09564962]\n# 0.11861282156685948\n# 0.020899470502765815\n# public score : 0.12176\n\n#xgb8\n# 0.12218887615283583.\n# [-0.12311578 -0.10393904 -0.11978129 -0.16208063 -0.10202764]\n# 0.11978128899996028\n# 0.021621929170878792\n# public score : 0.12340\n\n#xgb9\n# 0.12289801572950965\n# [-0.11956882 -0.11307731 -0.12082082 -0.16199867 -0.09902446]\n# 0.1195688216223085\n# 0.02102690141132909\n# public score : 0.12279\n\n#xgb10\n# 0.12189723833484438.\n# [-0.11769908 -0.11210582 -0.12542139 -0.15399192 -0.10026798]\n# 0.11769907780421265\n# 0.018021150486328682\n# public score : 0.12595\n\n#cb1\n# 0.12146870978524071\n# [-0.11689243 -0.11222937 -0.1195251  -0.1484336  -0.11026306]\n# 0.11689242795517175\n# 0.013876291530023033\n# public score : 0.12256\n\n#cb2\n# 0.12063624125827858\n# [-0.1156934  -0.10911198 -0.12282546 -0.15034066 -0.1052097 ]\n# 0.1156933974068409\n# 0.01601476634147856\n# public score : 0.12234\n\n#cb3\n# 0.12117629660914572\n# [-0.11685888 -0.11011589 -0.1235822  -0.1489466  -0.10637792]\n# 0.11685887726354985\n# 0.015079407156906926\n# public score : 0.12243\n\n#cb4\n# 0.12746553160273738.\n# [-0.12479513 -0.11602021 -0.12677251 -0.16181625 -0.10792355]\n# 0.1247951298785159\n# 0.01844162469894824\n# public score : 0.11767\n\n# 0.12657391647714436.\n# [-0.12250947 -0.11908302 -0.12198717 -0.16438165 -0.10490827]\n# 0.12198717243937014\n# 0.019962446238785396\n# public score : 0.11843\n\n#cb5\n# 0.12232080734704395\n# [-0.11730409 -0.10672066 -0.12218277 -0.15967962 -0.1057169 ]\n# 0.11730408572695568\n# 0.019697317031556482\n# public score : 0.12262\n\n#cb6\n# 0.1274473054822071\n# [-0.12410766 -0.11949513 -0.12663447 -0.15884384 -0.10815544]\n# 0.124107658094659\n# 0.01692908485762067\n# public score : 0.11918\n\n#lgbm1\n# 0.12052610219793292\n# [-0.11954391 -0.11328187 -0.11886363 -0.15219455 -0.09874655]\n# 0.11886362989527258\n# 0.01751254964107485\n# public score : 0.12100\n\n#lgbm2\n# 0.12006520251936215\n# [-0.1175394  -0.10907231 -0.12194504 -0.15602383 -0.09574543]\n# 0.11753940364579261\n# 0.020076009133654676\n# public score : 0.12188\n\n#lgbm3\n# 0.12476945989203363\n# [-0.12135222 -0.11226465 -0.1272039  -0.1535579  -0.10946863]\n# 0.12135222151106254\n# 0.015728090881840222\n# public score : 0.12432\n\n#lgbm4\n# 0.12056356608490129\n# [-0.12052822 -0.10662705 -0.12023993 -0.15732043 -0.0981022 ]\n# 0.12023993219991116\n# 0.020248023319354637\n# public score : 0.12081\n\n#lgbm5\n# 0.12194678876497556.\n# [-0.12324616 -0.10222344 -0.12207349 -0.16217016 -0.1000207 ]\n# 0.1220734899492754\n# 0.02231316891513297\n# public score : 0.12629\n\n#lgbm6\n# 0.1243739978569125.\n# [-0.12021403 -0.1201359  -0.11912219 -0.16589076 -0.0965071 ]\n# 0.1201359012486722\n# 0.02264091018759263\n# public score : 0.12429\n\n#rf\n# 0.13801475483285586.\n# [-0.1305587  -0.12929222 -0.14595504 -0.15818268 -0.12608512]\n# 0.13055870069685813\n# 0.0121965965512414\n# public score : 0.14004","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Among pipelines containing each of the 3 different models - XGB, CB and LGBM, the pipelines corresponding to best CV score and best public score was chosen for ensembling.\n\nThe best params for these pipelines are assigned below.","metadata":{}},{"cell_type":"code","source":"pipeline_xgb2.set_params(**best_params_xgb2)\npipeline_xgb7.set_params(**best_params_xgb7)\n\npipeline_cb2.set_params(**best_params_cb2)\n\npipeline_cb4_1 = clone(pipeline_cb4)\npipeline_cb4_2 = clone(pipeline_cb4)\npipeline_cb4_1.set_params(**best_params_cb4_1)\npipeline_cb4_2.set_params(**best_params_cb4_2)\n\npipeline_lgbm2.set_params(**best_params_lgbm2)\npipeline_lgbm4.set_params(**best_params_lgbm4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.385330Z","iopub.execute_input":"2025-04-22T11:48:02.385656Z","iopub.status.idle":"2025-04-22T11:48:02.530823Z","shell.execute_reply.started":"2025-04-22T11:48:02.385615Z","shell.execute_reply":"2025-04-22T11:48:02.529551Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"markdown","source":"## Voting Ensemble","metadata":{}},{"cell_type":"markdown","source":"This ensemble method combines the predictions of the base models by taking their average.","metadata":{}},{"cell_type":"code","source":"# Creating a custom class because VotingRegressor passes the data as numpy array to the individual estimators\n# But the pipelines used (i.e. the estimators for the VotingRegressor) expect Pandas DataFrame.\nclass CustomVotingRegressor(VotingRegressor):\n    def __init__(self, estimators, *, weights=None, n_jobs=None, verbose=False):\n        super().__init__(estimators=estimators, weights=weights, n_jobs=n_jobs, verbose=verbose)\n\n    def fit(self, X, y):\n        for name, estimator in self.estimators:\n            if hasattr(estimator, \"fit\"):\n                estimator.fit(X, y)\n        return self\n\n    def predict(self, X):\n        # Collect predictions from each estimator\n        predictions = []\n        for name, estimator in self.estimators:\n            if hasattr(estimator, \"predict\"):\n                predictions.append(estimator.predict(X))\n\n        # Combine predictions using weights\n        final_predictions = np.average(predictions, axis=0, weights=self.weights)\n\n        return final_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:48:02.531922Z","iopub.execute_input":"2025-04-22T11:48:02.532227Z","iopub.status.idle":"2025-04-22T11:48:02.539659Z","shell.execute_reply.started":"2025-04-22T11:48:02.532193Z","shell.execute_reply":"2025-04-22T11:48:02.538157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The cell below shows the definition and results for 3 different voting ensembles tried.","metadata":{}},{"cell_type":"code","source":"# best CV score ensemble\n# pipeline = CustomVotingRegressor([(\"xgb7\", pipeline_xgb7),\n#                                   (\"cb2\", pipeline_cb2),\n#                                   (\"lgbm2\", pipeline_lgbm2)])\n\n# [-0.11683245 -0.10538843 -0.11915497 -0.15306302 -0.09637309]\n# 0.11683245126666751\n# 0.019280847882660095\n# 0.11816239196799852\n# public score : 0.11982\n\n# best public score ensemble\npipeline = CustomVotingRegressor([(\"xgb2\", pipeline_xgb2),\n                                  (\"cb4_1\", pipeline_cb4_1),\n                                  (\"lgbm4\", pipeline_lgbm4)])\n\n# [-0.11909416 -0.10784494 -0.12015935 -0.15589714 -0.09967064]\n# 0.1190941614942\n# 0.019230481823789974\n# 0.12053324647111108\n# public score : 0.11756\n\n\n# best public score ensemble\n# pipeline = CustomVotingRegressor([(\"cb4_1\", pipeline_cb4_1),\n#                                   (\"cb4_2\", pipeline_cb4_2),\n#                                   (\"cb6\", pipeline_cb6)])\n# [-0.1230189  -0.11669888 -0.12419558 -0.16068482 -0.10595699]\n# 0.12301890277401711\n# 0.018457255239078416\n# 0.12611103443993923\n# public score : 0.11822","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Stacking Ensemble","metadata":{}},{"cell_type":"markdown","source":"This ensemble method takes the predictions from the base models as features for a new classifier called stacking classifier / final estimator, and the predictions from this classifier is taken as the final prediction. I've tried ExtraTreesRegressor, XGB, LGBM as stacking classifier.","metadata":{}},{"cell_type":"code","source":"class CustomStackingRegressor(StackingRegressor):\n    def __init__(self, estimators, final_estimator=None, *, cv=None, n_jobs=None, passthrough=False, verbose=0):\n        super().__init__(estimators=estimators, final_estimator=final_estimator, \n                         cv=cv, n_jobs=n_jobs, passthrough=passthrough, verbose=verbose)\n\n    def fit(self, X, y):\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"Input to fit must be a pandas DataFrame.\")        \n\n        # Fit all base estimators\n        self.base_estimators_ = []  # Store fitted base estimators\n        for name, estimator in self.estimators:\n            if hasattr(estimator, \"fit\"):\n                fitted_estimator = clone(estimator).fit(X, y)\n                self.base_estimators_.append((name, fitted_estimator))\n            else:\n                raise ValueError(f\"Estimator {name} does not implement a fit method.\")\n\n        # Generate predictions from base estimators for training the final estimator\n        meta_features = self._predict_base_estimators(X)\n\n        # Assign and fit the final estimator\n        if self.final_estimator is None:\n            self.final_estimator_ = RidgeCV(alphas=np.logspace(-6, 6, 13))\n        else:\n            self.final_estimator_ = clone(self.final_estimator)\n\n        self.final_estimator_.fit(meta_features, y)\n        return self\n\n    def predict(self, X):\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"Input to predict must be a pandas DataFrame.\")\n\n        # Generate predictions from base estimators\n        meta_features = self._predict_base_estimators(X)\n\n        # Use the final estimator to make predictions\n        return self.final_estimator_.predict(meta_features)\n\n    def _predict_base_estimators(self, X):\n        \"\"\"\n        Generate predictions from all base estimators and return as a DataFrame for meta-learning.\n        \"\"\"\n        predictions = []\n        for name, estimator in self.base_estimators_:\n            if hasattr(estimator, \"predict\"):\n                predictions.append(estimator.predict(X))\n            else:\n                raise ValueError(f\"Estimator {name} does not implement a predict method.\")\n\n        # Stack base predictions column-wise and return as a DataFrame\n        meta_features = pd.DataFrame(\n            np.column_stack(predictions),\n            columns=[name for name, _ in self.base_estimators_]\n        )\n        return meta_features","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The functions below are for optimizing the hyperparameters of the stacking classifier used for ensembling","metadata":{}},{"cell_type":"code","source":"# def et_stacking_objective(trial):  \n    \n#     params = {\n#         'n_estimators':          trial.suggest_int('n_estimators', 50, 300, step=10),  \n#         'max_depth':             trial.suggest_categorical('max_depth', [None] + list(range(3, 12))),  \n#         'min_samples_split':     trial.suggest_int('min_samples_split', 2, 10),  \n#         'min_samples_leaf':      trial.suggest_int('min_samples_leaf', 1, 10),  \n#         'max_features':          trial.suggest_categorical('max_features', [\"sqrt\", None, 0.5]), \n#         'bootstrap':             trial.suggest_categorical('bootstrap', [True, False]),  \n#         'min_impurity_decrease': trial.suggest_categorical('min_impurity_decrease', [0, 1e-6, 1e-5, 1e-4, 1e-3])  \n#     }\n\n#     final_estimator = ExtraTreesRegressor(random_state=SEED, **params)\n    \n#     pipeline = CustomStackingRegressor([(\"xgb2\", pipeline_xgb2),\n#                                         (\"cb4_1\", pipeline_cb4_1),\n#                                         (\"lgbm4\", pipeline_lgbm4)],\n#                                        final_estimator=final_estimator)    \n#     val_score = score_dataset(X, y, pipeline)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.enqueue_trial({'n_estimators': 200, 'max_depth': 10, \n#                     'min_samples_split': 3, 'min_samples_leaf': 5, \n#                     'max_features': None, 'bootstrap': False, \n#                     'min_impurity_decrease': 1e-05})\n# study.enqueue_trial({'n_estimators': 200, 'max_depth': 10, \n#                     'min_samples_split': 5, 'min_samples_leaf': 4, \n#                     'max_features': None, 'bootstrap': False, \n#                     'min_impurity_decrease': 1e-05})\n# study.enqueue_trial({'n_estimators': 200, 'max_depth': 7, \n#                     'min_samples_split': 10, 'min_samples_leaf': 4, \n#                     'max_features': 0.5, 'bootstrap': False, \n#                     'min_impurity_decrease': 1e-05})\n# study.optimize(et_stacking_objective, n_trials = 100)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"ETStack tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def xgb_stacking_objective(trial):  \n    \n#     params = {\n#         'n_estimators':             trial.suggest_int('n_estimators', 50, 300, step=10), \n#         'learning_rate':            trial.suggest_float('learning_rate', 0.001, 0.1, log=True),  \n#         'max_depth':                trial.suggest_int('max_depth', 2, 10),  \n#         'min_child_weight':         trial.suggest_int('min_child_weight', 1, 6),  \n#         'lambda':                   trial.suggest_float('lambda', 1e-3, 10.0, log=True),  \n#         'alpha':                    trial.suggest_float('alpha', 1e-3, 10.0, log=True),  \n#         'subsample':                trial.suggest_float('subsample', 0.6, 1.0, step=0.05),  \n#         'colsample_bytree':         trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05)  \n#     }\n#     final_estimator = XGBRegressor(random_state = SEED, **params)\n#     pipeline = CustomStackingRegressor([(\"xgb2\", pipeline_xgb2),\n#                                         (\"cb4_1\", pipeline_cb4_1),\n#                                         (\"lgbm4\", pipeline_lgbm4)],\n#                                        final_estimator=final_estimator)      \n#     val_score = score_dataset(X, y, pipeline)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.enqueue_trial({'n_estimators': 150, 'learning_rate': 0.07375950393946418, \n#                      'max_depth': 3, 'min_child_weight': 5, \n#                      'lambda': 0.025091460051336875, 'alpha': 0.26969435515966034, \n#                      'subsample': 0.75, 'colsample_bytree': 1.0})\n# study.optimize(xgb_stacking_objective, n_trials = 100)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"XGBStack tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def lgbm_stacking_objective(trial):  \n    \n#     params = {\n#         'n_estimators':             trial.suggest_int('n_estimators', 100, 1000, step=50), \n#         'learning_rate':            trial.suggest_float('learning_rate', 0.001, 0.1, log=True),  \n#         'max_depth':                trial.suggest_int('max_depth', 2, 10),  \n#         'min_child_weight':         trial.suggest_int('min_child_weight', 1, 6),  \n#         'lambda':                   trial.suggest_float('lambda', 1e-3, 10.0, log=True),  \n#         'alpha':                    trial.suggest_float('alpha', 1e-3, 10.0, log=True),  \n#         'subsample':                trial.suggest_float('subsample', 0.6, 1.0, step=0.05),  \n#         'colsample_bytree':         trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05)  \n#     }\n#     final_estimator = LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1, **params)\n#     pipeline = CustomStackingRegressor([(\"xgb2\", pipeline_xgb2),\n#                                         (\"cb4_1\", pipeline_cb4_1),\n#                                         (\"lgbm4\", pipeline_lgbm4)],\n#                                        final_estimator=final_estimator)   \n#     val_score = score_dataset(X, y, pipeline)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(lgbm_stacking_objective, n_trials = 50)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"LGBMStack tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The cells below shows the best hyperparameters, definition and results for 2*3 different stacking ensembles tried.","metadata":{}},{"cell_type":"code","source":"# best_params_stack_1_et = {'n_estimators': 150, 'max_depth': 9, 'min_samples_split': 9, \n#                           'min_samples_leaf': 1, 'max_features': 0.5, \n#                           'bootstrap': True, 'min_impurity_decrease': 1e-06}\n# final_estimator = ExtraTreesRegressor(random_state=SEED, **best_params_stack_1_et)\n# # Best is trial 96 with value: 0.11811866066958998.\n# # [-0.11734512 -0.10611117 -0.11802932 -0.15376507 -0.09534262]\n# # 0.11734512463400401\n# # 0.019668250006962325\n# public score : 0.11992\n\n# best_params_stack_1_xgb = {'n_estimators': 190, 'learning_rate': 0.08769177958535646, \n#                            'max_depth': 7, 'min_child_weight': 6, 'lambda': 0.086495311711192, \n#                            'alpha': 1.410568758087574, 'subsample': 0.65, 'colsample_bytree': 0.65}\n# final_estimator = XGBRegressor(random_state = SEED, **best_params_stack_1_xgb)\n# # Best is trial 89 with value: 0.11859734903879329.\n# # [-0.1162992  -0.11061317 -0.11796542 -0.14896509 -0.09914387]\n# # 0.11629920408371323\n# # 0.016553340014904726\n# public score : 0.12011\n\n# best_params_stack_1_lgbm = {'n_estimators': 450, 'learning_rate': 0.010840522748967163, \n#                             'max_depth': 3, 'min_child_weight': 5, 'lambda': 3.3906080499991837, \n#                             'alpha': 0.003051846651081862, 'subsample': 0.75, 'colsample_bytree': 0.95}\n# final_estimator = LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1, **best_params_stack_1_lgbm)\n# # Best is trial 43 with value: 0.12087691224407573.\n# # [-0.12269626 -0.11534181 -0.11637662 -0.1502804  -0.09968947]\n# # 0.11637662226846344\n# # 0.01653887974797546\n# public score : 0.12159\n\n# pipeline = CustomStackingRegressor([(\"xgb7\", pipeline_xgb7),\n#                                     (\"cb2\", pipeline_cb2),\n#                                     (\"lgbm2\", pipeline_lgbm2)],\n#                                    final_estimator=final_estimator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_params_stack_2_et = {'n_estimators': 220, 'max_depth': 7, 'min_samples_split': 3, \n#                           'min_samples_leaf': 6, 'max_features': None, \n#                           'bootstrap': False, 'min_impurity_decrease': 1e-06}\n# final_estimator = ExtraTreesRegressor(random_state=SEED, **best_params_stack_2_et)\n# # Best is trial 80 with value: 0.1192352445126231.\n# # [-0.11904213 -0.10864097 -0.11902749 -0.14953201 -0.09993363]\n# # 0.11902749083788132\n# # 0.01674972014959425\n# public score : 0.11795\n\n# best_params_stack_2_xgb = {'n_estimators': 120, 'learning_rate': 0.08323395974043807, \n#                            'max_depth': 5, 'min_child_weight': 2, 'lambda': 0.01966703130433511, \n#                            'alpha': 1.5843093533338586, 'subsample': 0.85, 'colsample_bytree': 0.8}\n# final_estimator = XGBRegressor(random_state = SEED, **best_params_stack_2_xgb)\n# # Best is trial 41 with value: 0.11906722703760253.\n# # [-0.11932822 -0.11207885 -0.11744712 -0.14669344 -0.0997885 ]\n# # 0.11744712156659413\n# # 0.015403944333192962\n# public score : 0.11810\n\n# best_params_stack_2_lgbm = {'n_estimators': 400, 'learning_rate': 0.01777858244157366, \n#                             'max_depth': 2, 'min_child_weight': 5, 'lambda': 7.932044228972671, \n#                             'alpha': 0.8645676421523685, 'subsample': 0.7, 'colsample_bytree': 0.6}\n# final_estimator = LGBMRegressor(random_state = SEED, bagging_seed = SEED, verbose = -1, **best_params_stack_2_lgbm)\n# # Best is trial 14 with value: 0.12029488765955257.\n# # [-0.12039283 -0.11591539 -0.11684868 -0.14817247 -0.10014507]\n# # 0.11684867795871483\n# # 0.015583586739827472\n# public score : 0.11983\n\n# pipeline = CustomStackingRegressor([(\"xgb2\", pipeline_xgb2),\n#                                     (\"cb4_1\", pipeline_cb4_1),\n#                                     (\"lgbm4\", pipeline_lgbm4)],\n#                                    final_estimator=final_estimator) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train on full data and obtain test predictions","metadata":{}},{"cell_type":"code","source":"#retrain on full data and obtain test predictions using best model hyperparameter values\npipeline.fit(X, np.log(y))\n\n# Preprocessing of validation data, get predictions\npred = np.exp(pipeline.predict(X_test))\n\nprint(pred[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T06:56:59.714747Z","iopub.execute_input":"2025-04-15T06:56:59.715117Z","iopub.status.idle":"2025-04-15T06:57:03.426175Z","shell.execute_reply.started":"2025-04-15T06:56:59.715085Z","shell.execute_reply":"2025-04-15T06:57:03.425215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipeline","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': pred})\noutput.to_csv('submission.csv', index=False)\nprint('saved output file')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-14T07:14:39.409Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# References\n- sklearn pipeline : https://www.kaggle.com/code/alexisbcook/pipelines\n- https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices\n- https://www.kaggle.com/code/marto24/beginners-prediction-top3","metadata":{}},{"cell_type":"markdown","source":"Please upvote if you found this notebook helpful : https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2","metadata":{}}]}