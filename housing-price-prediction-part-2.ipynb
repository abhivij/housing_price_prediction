{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is a cleaned up version of https://www.kaggle.com/code/abhivij/housing-price-prediction-part-2-exploratory ","metadata":{}},{"cell_type":"markdown","source":"# References\n- sklearn pipeline : https://www.kaggle.com/code/alexisbcook/pipelines\n- https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices\n- https://www.kaggle.com/code/marto24/beginners-prediction-top3","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom pandas.api.types import CategoricalDtype\n\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.feature_selection import mutual_info_regression\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.base import BaseEstimator, TransformerMixin, clone\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, PowerTransformer\n\nfrom functools import reduce\n\nfrom category_encoders import MEstimateEncoder, cat_boost\n\nfrom sklearn.compose import ColumnTransformer\n\nimport optuna\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-01-18T10:48:16.316175Z","iopub.execute_input":"2025-01-18T10:48:16.316627Z","iopub.status.idle":"2025-01-18T10:48:16.323394Z","shell.execute_reply.started":"2025-01-18T10:48:16.316594Z","shell.execute_reply":"2025-01-18T10:48:16.321983Z"},"trusted":true},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"SEED = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.324799Z","iopub.execute_input":"2025-01-18T10:48:16.325171Z","iopub.status.idle":"2025-01-18T10:48:16.353942Z","shell.execute_reply.started":"2025-01-18T10:48:16.325144Z","shell.execute_reply":"2025-01-18T10:48:16.352700Z"}},"outputs":[],"execution_count":91},{"cell_type":"markdown","source":"# Load data and preprocess function","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data(train_data = True, perform_impute = True):\n    if train_data:\n        print(\"Train data\")\n        X = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\n        X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n        y = X.SalePrice\n        X.drop(['SalePrice'], axis=1, inplace=True)\n    else:\n        print(\"Test data\")\n        X = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\n        y = None\n    print(\"Loaded data\")\n    print(X.shape)\n\n    X[\"GarageYrBlt\"] = X[\"GarageYrBlt\"].where((X.GarageYrBlt.isna() | (X.GarageYrBlt <= 2024)), X.YearRemodAdd)  #there is 1 GarageYrBlt with value 2207\n    X[\"Exterior2nd\"] = X[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    \n    X = encode(X)\n    if perform_impute:\n        X = impute(X)\n    \n    return (X, y)\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name] = df[name].cat.add_categories(\"None\")\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df\n\ndef impute(df):\n    df.loc[df.GarageYrBlt.isna() & df.GarageType.notna(), \"GarageYrBlt\"] = df.YearRemodAdd\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.355605Z","iopub.execute_input":"2025-01-18T10:48:16.355958Z","iopub.status.idle":"2025-01-18T10:48:16.378725Z","shell.execute_reply.started":"2025-01-18T10:48:16.355919Z","shell.execute_reply":"2025-01-18T10:48:16.377575Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"# Categorical features - special handling\nRef : https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices","metadata":{}},{"cell_type":"code","source":"# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \n                \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \n                \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\",\n                \"Fence\", \"Electrical\"]\n\n\n# The ordinal (ordered) categorical features \nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(1, 11))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"IR3\", \"IR2\", \"IR1\", \"Reg\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"ELO\", \"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"]\n}\n\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\nordered_levels.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.380580Z","iopub.execute_input":"2025-01-18T10:48:16.381024Z","iopub.status.idle":"2025-01-18T10:48:16.411096Z","shell.execute_reply.started":"2025-01-18T10:48:16.380979Z","shell.execute_reply":"2025-01-18T10:48:16.409631Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"dict_keys(['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC', 'LotShape', 'LandSlope', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'GarageFinish', 'PavedDrive', 'Utilities', 'CentralAir'])"},"metadata":{}}],"execution_count":93},{"cell_type":"markdown","source":"# Append features","metadata":{}},{"cell_type":"code","source":"ms_subclass_mapping = {\n    20: \"1-STORY 1946 & NEWER ALL STYLES\",\n    30: \"1-STORY 1945 & OLDER\",\n    40: \"1-STORY W/FINISHED ATTIC ALL AGES\",\n    45: \"1-1/2 STORY - UNFINISHED ALL AGES\",\n    50: \"1-1/2 STORY FINISHED ALL AGES\",\n    60: \"2-STORY 1946 & NEWER\",\n    70: \"2-STORY 1945 & OLDER\",\n    75: \"2-1/2 STORY ALL AGES\",\n    80: \"SPLIT OR MULTI-LEVEL\",\n    85: \"SPLIT FOYER\",\n    90: \"DUPLEX - ALL STYLES AND AGES\",\n    120: \"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\",\n    150: \"1-1/2 STORY PUD - ALL AGES\",\n    160: \"2-STORY PUD - 1946 & NEWER\",\n    180: \"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\",\n    190: \"2 FAMILY CONVERSION - ALL STYLES AND AGES\"\n}\n\nms_class_mapping = {\n    \"1-STORY 1946 & NEWER ALL STYLES\": \"1-Story\",\n    \"1-STORY 1945 & OLDER\": \"1-Story\",\n    \"1-STORY W/FINISHED ATTIC ALL AGES\": \"1-Story\",\n    \"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\": \"1-Story\",\n    \"1-1/2 STORY - UNFINISHED ALL AGES\": \"1-1/2 Story\",\n    \"1-1/2 STORY FINISHED ALL AGES\": \"1-1/2 Story\",\n    \"1-1/2 STORY PUD - ALL AGES\": \"1-1/2 Story\",\n    \"2-STORY 1946 & NEWER\": \"2-Story\",\n    \"2-STORY 1945 & OLDER\": \"2-Story\",\n    \"2-STORY PUD - 1946 & NEWER\": \"2-Story\",\n    \"SPLIT OR MULTI-LEVEL\": \"Split-Level\",\n    \"SPLIT FOYER\": \"Split-Level\",\n    \"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\": \"Split-Level\",\n    \"DUPLEX - ALL STYLES AND AGES\": \"Multi-Family/Duplex\",\n    \"2 FAMILY CONVERSION - ALL STYLES AND AGES\": \"Multi-Family/Duplex\",\n    \"2-1/2 STORY ALL AGES\": \"2-1/2 Story\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.412763Z","iopub.execute_input":"2025-01-18T10:48:16.413165Z","iopub.status.idle":"2025-01-18T10:48:16.438013Z","shell.execute_reply.started":"2025-01-18T10:48:16.413131Z","shell.execute_reply":"2025-01-18T10:48:16.436809Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"def append_features(df):\n    df = df.copy()\n\n    #The commented features below ended up decreasing the overall score\n    \n    df[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    # df[\"Spaciousness\"] = (df['1stFlrSF'] + df['2ndFlrSF']) / df.TotRmsAbvGrd\n    # df[\"Spaciousness\"] = df.GrLivArea / df.TotRmsAbvGrd\n    df[\"Spaciousness\"] = df.GrLivArea / (df.TotRmsAbvGrd + df.FullBath + df.HalfBath + df.KitchenAbvGr)\n\n    # df[\"Age\"] = df.YrSold - df.YearBuilt\n    # df[\"Age_since_mod\"] = df.YrSold - df.YearRemodAdd\n    # print(df.Age_since_mod.describe())\n\n    # bldg_dummies = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    # df = df.join(bldg_dummies.mul(df.GrLivArea, axis=0))\n    \n    # df[\"PorchTypes\"] = df[[\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\"]].gt(0.0).sum(axis=1)\n\n    # df[\"TotalOutsideSF\"] = df.WoodDeckSF + df.OpenPorchSF + df.EnclosedPorch + df[\"3SsnPorch\"] + df.ScreenPorch\n\n    df[\"MSClass\"] = (X[\"MSSubClass\"].map(ms_subclass_mapping)\n                                    .map(ms_class_mapping)\n                                    .astype('category')\n                                    .cat.add_categories(\"None\")\n                                    .fillna(\"None\"))\n    df[\"IsPUD\"] = (X[\"MSSubClass\"].map(ms_subclass_mapping)\n                                  .str.contains('PUD')\n                                  .astype('category')\n                                  .cat.add_categories(\"None\")\n                                  .fillna(\"None\"))\n    # df.drop(columns = \"MSSubClass\", inplace = True)\n\n    # df[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n\n    # #PCA inspired as specified in https://www.kaggle.com/code/ryanholbrook/feature-engineering-for-house-prices\n    # df[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    # df[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n\n    # df[\"OverallScore\"] = df.OverallQual.cat.codes * df.OverallCond.cat.codes\n    # df[\"OverallScore\"] = df.OverallQual.cat.codes + df.OverallCond.cat.codes\n\n    # df[\"LotAreaFrontage\"] = df.LotArea * (df.LotFrontage + 21.0/10)  \n    #                                     # adding a small value to avoid effect of 0 LotFrontage. \n    #                                     # 21 is minimum LotFrontage before replacing NA with 0\n    # df[\"LotAreaFrontage\"] = df.LotArea * df.LotFrontage\n\n    # df[\"Age_with_quality\"] = (df.YrSold - df.YearBuilt) * df.OverallQual.cat.codes \n\n    # df[\"TotalBathrooms\"] = df.FullBath + (0.5 * df.HalfBath) + df.BsmtFullBath + (0.5 * df.BsmtHalfBath)\n\n    df[\"GarageAreaPerCar\"] = df.GarageArea / (df.GarageCars + 0.1)\n    # print(df[\"GarageAreaPerCar\"].describe())\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.524988Z","iopub.execute_input":"2025-01-18T10:48:16.525362Z","iopub.status.idle":"2025-01-18T10:48:16.535066Z","shell.execute_reply.started":"2025-01-18T10:48:16.525330Z","shell.execute_reply":"2025-01-18T10:48:16.533444Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"# Load data and process","metadata":{}},{"cell_type":"code","source":"X, y = load_and_preprocess_data()\nX_test, _ = load_and_preprocess_data(train_data = False)\n\nprint(\"removing less important features\")\nfeatures_to_drop = ['PoolQC', 'MiscVal', 'MoSold', 'PoolArea', 'MiscFeature', 'Utilities']\nX.drop(columns = features_to_drop, inplace = True)\nX_test.drop(columns = features_to_drop, inplace = True)\nprint(X.shape)\nprint(X_test.shape)\n\nprint(\"appending features\")\nX = append_features(X)\nprint(X.shape)\nX_test = append_features(X_test)\nprint(X_test.shape)\n\ndef remove_columns_from_list(orig_list, to_remove):\n    return [f for f in orig_list if f not in to_remove]\n    \nordinal_categorical_cols = remove_columns_from_list(ordered_levels.keys(), features_to_drop)\nfeatures_nom = remove_columns_from_list(features_nom, features_to_drop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.536493Z","iopub.execute_input":"2025-01-18T10:48:16.536855Z","iopub.status.idle":"2025-01-18T10:48:16.763765Z","shell.execute_reply.started":"2025-01-18T10:48:16.536809Z","shell.execute_reply":"2025-01-18T10:48:16.762423Z"}},"outputs":[{"name":"stdout","text":"Train data\nLoaded data\n(1460, 79)\nTest data\nLoaded data\n(1459, 79)\nremoving less important features\n(1460, 73)\n(1459, 73)\nappending features\n(1460, 78)\n(1459, 78)\n","output_type":"stream"}],"execution_count":96},{"cell_type":"markdown","source":"# Append Cluster information as training features","metadata":{}},{"cell_type":"code","source":"class AppendKMeans(BaseEstimator, TransformerMixin):\n    def __init__(self, cluster_columns, n_clusters=20, return_cluster=True, return_distances=False):\n        self.cluster_columns = cluster_columns\n        self.n_clusters = n_clusters\n        self.return_cluster = return_cluster\n        self.return_distances = return_distances\n\n    def fit(self, X, y=None):\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        self.scaler = StandardScaler()\n        X_scaled = self.scaler.fit_transform(X[self.cluster_columns])  # Scale features\n        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=SEED)\n        self.kmeans.fit(X_scaled)  # Fit K-Means on scaled features\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        X_scaled = self.scaler.transform(X[self.cluster_columns])  # Apply same scaling as training\n        if self.return_cluster:\n            result[\"Cluster\"] = self.kmeans.predict(X_scaled)  # Get cluster\n        if self.return_distances:\n            cluster_distances = self.kmeans.transform(X_scaled)\n            cluster_distances = pd.DataFrame(\n                    cluster_distances, columns=[f\"distance_centroid_{i}\" for i in range(cluster_distances.shape[1])]\n            )\n            cluster_distances.set_index(X.index, inplace = True)\n            result = result.join(cluster_distances)\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.766621Z","iopub.execute_input":"2025-01-18T10:48:16.766999Z","iopub.status.idle":"2025-01-18T10:48:16.776004Z","shell.execute_reply.started":"2025-01-18T10:48:16.766964Z","shell.execute_reply":"2025-01-18T10:48:16.774726Z"}},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":"# Append PCA","metadata":{}},{"cell_type":"code","source":"class AppendPCA(BaseEstimator, TransformerMixin):\n    def __init__(self, pca_columns, n_components=2, pca_col_prefix=\"PCA\"):\n        self.pca_columns = pca_columns\n        self.n_components = n_components\n        self.pca_col_prefix = pca_col_prefix\n\n    def fit(self, X, y=None):\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        self.scaler = StandardScaler()\n        X_scaled = self.scaler.fit_transform(X[self.pca_columns])  # Scale features\n        self.pca = PCA(n_components=self.n_components, random_state=SEED)\n        self.pca.fit(X_scaled)  # Fit PCA on scaled features\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        X = X.copy()\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n        X_scaled = self.scaler.transform(X[self.pca_columns])  # Apply same scaling as training\n        pca_components = self.pca.transform(X_scaled)  # Apply PCA\n        # print(self.pca.explained_variance_ratio_)\n        # print(np.cumsum(self.pca.explained_variance_ratio_))\n        pca_components = pd.DataFrame(\n                    pca_components, columns=[f\"{self.pca_col_prefix}_{i}\" for i in range(pca_components.shape[1])]\n        )\n        pca_components.set_index(X.index, inplace = True)\n        result = result.join(pca_components)\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.777528Z","iopub.execute_input":"2025-01-18T10:48:16.777856Z","iopub.status.idle":"2025-01-18T10:48:16.797511Z","shell.execute_reply.started":"2025-01-18T10:48:16.777826Z","shell.execute_reply":"2025-01-18T10:48:16.796540Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"# Target Encoding","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder(BaseEstimator, TransformerMixin):\n    \n    #encoder_other_params should be a dict of argument_name and value\n    # This is done to ensure it works properly within Pipeline\n    # Not passing it as kwargs, because Pipeline uses sklearn.base.clone() and clone does not retain kwargs\n    def __init__(self, cols, encoder, encoder_other_params):\n        self.cols = cols\n        self.encoder = encoder\n        self.cv = KFold(n_splits=5)\n        self.encoder_other_params = encoder_other_params  \n        \n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit(self, X, y):\n        self.fitted_encoders_ = []\n        X_encoded = []\n        for idx_encode, _ in self.cv.split(X):\n            fitted_encoder = self.encoder(cols=self.cols, **self.encoder_other_params)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            self.fitted_encoders_.append(fitted_encoder)\n        return self\n\n    # To transform the data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        #drop columns for which target encoding has been created and join with target encodings\n        return X.drop(columns=self.cols).join(X_encoded)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.798631Z","iopub.execute_input":"2025-01-18T10:48:16.799026Z","iopub.status.idle":"2025-01-18T10:48:16.822817Z","shell.execute_reply.started":"2025-01-18T10:48:16.798988Z","shell.execute_reply":"2025-01-18T10:48:16.821625Z"}},"outputs":[],"execution_count":99},{"cell_type":"markdown","source":"# Training pipeline","metadata":{}},{"cell_type":"markdown","source":"Lets define a Transformer to convert categorical columns to their codes","metadata":{}},{"cell_type":"code","source":"class OrdinalEncoder(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        for col in result.columns:\n            result[col] = result[col].cat.codes\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.824036Z","iopub.execute_input":"2025-01-18T10:48:16.824411Z","iopub.status.idle":"2025-01-18T10:48:16.849072Z","shell.execute_reply.started":"2025-01-18T10:48:16.824369Z","shell.execute_reply":"2025-01-18T10:48:16.848003Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"categorical_cols = [cname for cname in X.columns if\n                    X[cname].dtype == \"category\"]\n\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\nsmall_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() <= 4 and cname not in ordinal_categorical_cols]\nmed_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() > 4 and X[cname].nunique() < 10 and cname not in ordinal_categorical_cols]\nlarge_cat_categorical_cols = [cname for cname in categorical_cols if\n                             X[cname].nunique() >= 10 and cname not in ordinal_categorical_cols]\n\nprint(len(ordinal_categorical_cols))\nprint(len(small_cat_categorical_cols))\nprint(len(med_cat_categorical_cols))\nprint(len(large_cat_categorical_cols))\nprint(len(categorical_cols))  \nprint(len(numerical_cols))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.850019Z","iopub.execute_input":"2025-01-18T10:48:16.850298Z","iopub.status.idle":"2025-01-18T10:48:16.893712Z","shell.execute_reply.started":"2025-01-18T10:48:16.850265Z","shell.execute_reply":"2025-01-18T10:48:16.892668Z"}},"outputs":[{"name":"stdout","text":"20\n5\n16\n4\n45\n33\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor()):\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    log_y = np.log(y)\n    score = cross_val_score(\n        model, X, log_y, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs = -1\n    )\n    print(score)\n    print(-1*np.median(score))\n    print(np.std(score))\n    score = -1 * np.mean(score)\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.894717Z","iopub.execute_input":"2025-01-18T10:48:16.895047Z","iopub.status.idle":"2025-01-18T10:48:16.900900Z","shell.execute_reply.started":"2025-01-18T10:48:16.895019Z","shell.execute_reply":"2025-01-18T10:48:16.899531Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"# Pipeline 1\n# numerical_transformer = Pipeline(steps=[\n#     ('scaler', StandardScaler())\n# ])\n# ord_categorical_transformer = Pipeline(steps=[\n#     ('catcode', OrdinalEncoder())\n# ])\n# small_categorical_transformer = Pipeline(steps=[\n#     ('small_cat_catcode', OrdinalEncoder())\n# ])\n\n# pipeline = Pipeline([\n#     ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n#     ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n#                                         encoder=MEstimateEncoder, \n#                                         encoder_other_params={\"m\":10.0})),\n#     ('encoder_scaler', ColumnTransformer(\n#         transformers=[\n#             ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n#             ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n#             ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n#         ],\n#         remainder=\"passthrough\")\n#     ),\n#     ('model', XGBRegressor())         \n# ])\n# score_dataset(X, y, pipeline)\n\n# [-0.12334956 -0.13390977 -0.13267923 -0.11532492 -0.12691669]\n# 0.12691668822938887\n# 0.006753496607733489\n# 0.12643603427331637","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.903582Z","iopub.execute_input":"2025-01-18T10:48:16.904152Z","iopub.status.idle":"2025-01-18T10:48:16.921177Z","shell.execute_reply.started":"2025-01-18T10:48:16.904113Z","shell.execute_reply":"2025-01-18T10:48:16.919994Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"# Pipeline 2\n# numerical_transformer = Pipeline(steps=[\n#     ('scaler', StandardScaler())\n# ])\n# ord_categorical_transformer = Pipeline(steps=[\n#     ('catcode', OrdinalEncoder()),\n#     ('scaler', StandardScaler())\n# ])\n# small_categorical_transformer = Pipeline(steps=[\n#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n# ])\n\n\n# pipeline = Pipeline([\n#     ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n#     ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n#                                         encoder=MEstimateEncoder, \n#                                         encoder_other_params={\"m\":10.0})),\n#     ('encoder_scaler', ColumnTransformer(\n#         transformers=[\n#             ('num', numerical_transformer, numerical_cols+[col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n#             ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n#             ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n#         ],\n#         remainder=\"passthrough\")\n#     ),\n#     ('model', XGBRegressor())         \n# ])\n\n# score_dataset(X, y, pipeline)\n\n# # [-0.12328024 -0.14403148 -0.14249333 -0.11536911 -0.12724898]\n# # 0.12724898077297406\n# # 0.011122748447938504\n# # 0.1304846298772378","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.922458Z","iopub.execute_input":"2025-01-18T10:48:16.922777Z","iopub.status.idle":"2025-01-18T10:48:16.947437Z","shell.execute_reply.started":"2025-01-18T10:48:16.922750Z","shell.execute_reply":"2025-01-18T10:48:16.946001Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"# Pipeline 3\n# numerical_transformer = Pipeline(steps=[\n#     ('scaler', StandardScaler())\n# ])\n# ord_categorical_transformer = Pipeline(steps=[\n#     ('catcode', OrdinalEncoder()),\n#     ('scaler', StandardScaler())\n# ])\n# small_categorical_transformer = Pipeline(steps=[\n#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n# ])\n\n\n# pipeline = Pipeline([\n#     ('append_pca', AppendPCA(X.columns, n_components = 5)), \n#     ('append_kmeans', AppendKMeans([f\"PCA_{i}\" for i in range(5)], \n#                                    n_clusters = 10,\n#                                    return_cluster=True, return_distances=True)),\n#     ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n#                                         encoder=MEstimateEncoder, \n#                                         encoder_other_params={\"m\":10.0})),\n#     ('encoder_scaler', ColumnTransformer(\n#         transformers=[\n#             ('num', numerical_transformer, (numerical_cols + \n#                                            [col + \"_encoded\" for col in large_cat_categorical_cols] + \n#                                            [f\"PCA_{i}\" for i in range(5)] + \n#                                            [f\"distance_centroid_{i}\" for i in range(10)])\n#             ),\n#             ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n#             ('small_cat', small_categorical_transformer, small_cat_categorical_cols+['Cluster'])\n#         ],\n#         remainder=\"passthrough\")\n#     ),\n#     ('model', XGBRegressor())         \n# ])\n\n# score_dataset(X, y, pipeline)\n\n# # [-0.12575089 -0.14977669 -0.14573617 -0.11280657 -0.12453592]\n# # 0.12575089246295004\n# # 0.013910111600061406\n# # 0.13172124644075708","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.948549Z","iopub.execute_input":"2025-01-18T10:48:16.948965Z","iopub.status.idle":"2025-01-18T10:48:16.970928Z","shell.execute_reply.started":"2025-01-18T10:48:16.948920Z","shell.execute_reply":"2025-01-18T10:48:16.969515Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"# Pipeline 4\n# numerical_transformer = Pipeline(steps=[\n#     ('scaler', StandardScaler())\n# ])\n# ord_categorical_transformer = Pipeline(steps=[\n#     ('catcode', OrdinalEncoder())\n# ])\n# small_categorical_transformer = Pipeline(steps=[\n#     ('small_cat_catcode', OrdinalEncoder())\n# ])\n\n# pipeline = Pipeline([\n#     ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n#     ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n#                                         encoder=MEstimateEncoder, \n#                                         encoder_other_params={\"m\":10.0})),\n#     ('encoder_scaler', ColumnTransformer(\n#         transformers=[\n#             ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n#             ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n#             ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n#         ],\n#         remainder=\"passthrough\")\n#     ),\n#     ('model', RandomForestRegressor())         \n# ])\n# score_dataset(X, y, pipeline)\n# [-0.13334223 -0.14826003 -0.14243637 -0.12530829 -0.13019875]\n# 0.13334223315889074\n# 0.008327364089523639\n# 0.1359091355635815","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.972109Z","iopub.execute_input":"2025-01-18T10:48:16.972422Z","iopub.status.idle":"2025-01-18T10:48:16.996054Z","shell.execute_reply.started":"2025-01-18T10:48:16.972371Z","shell.execute_reply":"2025-01-18T10:48:16.994845Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"# Pipeline 5\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\nord_categorical_transformer = Pipeline(steps=[\n    ('catcode', OrdinalEncoder())\n])\nsmall_categorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\nmed_categorical_transformer = Pipeline(steps=[\n    ('catcode_medcat', OrdinalEncoder())\n])\n\npipeline = Pipeline([\n    ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n    ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n                                        encoder=MEstimateEncoder, \n                                        encoder_other_params={\"m\":10.0})),\n    ('encoder_scaler', ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, [col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n            ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n            ('med_cat', med_categorical_transformer, med_cat_categorical_cols),\n            ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n        ],\n        remainder=\"passthrough\")\n    ),\n    ('model', XGBRegressor())         \n])\n\nscore_dataset(X, y, pipeline)\n\n# [-0.12651235 -0.13380629 -0.13357361 -0.11428085 -0.12639507]\n# 0.12651234561050542\n# 0.007097623139040923\n# 0.126913633236225\n\n# med_cat [> 5 and < 10]\n# [-0.12506024 -0.14160065 -0.13534954 -0.11813159 -0.11999781]\n# 0.12506024282103534\n# 0.00904491349257496\n# 0.12802796794855642\n\n# med_cat [> 6 and < 10]\n# [-0.1277651  -0.14225836 -0.13436323 -0.11917849 -0.12597884]\n# 0.12776509761340055\n# 0.007842616722643862\n# 0.12990880359437723\n\n# med_cat [> 4 and < 10]\n# [-0.12548204 -0.142939   -0.13416994 -0.11402189 -0.12682665]\n# 0.12682664692146164\n# 0.009612285820809875\n# 0.12868790109795897","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T10:48:16.997206Z","iopub.execute_input":"2025-01-18T10:48:16.997574Z","iopub.status.idle":"2025-01-18T10:48:19.813154Z","shell.execute_reply.started":"2025-01-18T10:48:16.997529Z","shell.execute_reply":"2025-01-18T10:48:19.811826Z"}},"outputs":[{"name":"stdout","text":"[-0.12548204 -0.142939   -0.13416994 -0.11402189 -0.12682665]\n0.12682664692146164\n0.009612285820809875\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"0.12868790109795897"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"# Pipeline 6\n# numerical_transformer = Pipeline(steps=[\n#     ('skew_handler', PowerTransformer(method='yeo-johnson', standardize=False)),\n#     ('scaler', RobustScaler())\n# ])\n# ord_categorical_transformer = Pipeline(steps=[\n#     ('catcode', OrdinalEncoder()),\n#     ('scaler', RobustScaler())\n# ])\n# small_categorical_transformer = Pipeline(steps=[\n#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n# ])\n\n\n# pipeline = Pipeline([\n#     ('append_pca', AppendPCA(X.columns, n_components = 5)),  \n#     ('append_target_encoder', CrossFoldEncoder(cols=large_cat_categorical_cols, \n#                                         encoder=MEstimateEncoder, \n#                                         encoder_other_params={\"m\":10.0})),\n#     ('encoder_scaler', ColumnTransformer(\n#         transformers=[\n#             ('num', numerical_transformer, numerical_cols+[col + \"_encoded\" for col in large_cat_categorical_cols]+[f\"PCA_{i}\" for i in range(5)]),\n#             ('ord_cat', ord_categorical_transformer, ordinal_categorical_cols),\n#             ('small_cat', small_categorical_transformer, small_cat_categorical_cols)\n#         ],\n#         remainder=\"passthrough\")\n#     ),\n#     ('model', XGBRegressor())         \n# ])\n\n# score_dataset(X, y, pipeline)\n\n# [-0.12212421 -0.14414503 -0.14381811 -0.11467164 -0.12970438]\n# 0.12970437937124102\n# 0.011697107907623815\n# 0.13089267445607045","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T08:04:59.199900Z","iopub.execute_input":"2025-01-18T08:04:59.200298Z","iopub.status.idle":"2025-01-18T08:05:02.495663Z","shell.execute_reply.started":"2025-01-18T08:04:59.200264Z","shell.execute_reply":"2025-01-18T08:05:02.494797Z"}},"outputs":[{"name":"stdout","text":"[-0.12212421 -0.14414503 -0.14381811 -0.11467164 -0.12970438]\n0.12970437937124102\n0.011697107907623815\n","output_type":"stream"},{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"0.13089267445607045"},"metadata":{}}],"execution_count":127},{"cell_type":"markdown","source":"# Optimize hyperparameters","metadata":{}},{"cell_type":"code","source":"def xgb_objective(trial):  \n    \n    params = {\n        'model__random_state':       SEED,\n        'model__n_estimators':       trial.suggest_int('model__n_estimators', 500, 2000, step = 50),\n        'model__learning_rate':      trial.suggest_float('model__learning_rate', 1e-4, 0.5, log=True),\n        'model__max_depth':          trial.suggest_int('model__max_depth', 0, 8),\n        'model__min_child_weight':   trial.suggest_int('model__min_child_weight', 0, 10),\n        'model__lambda':             trial.suggest_float('model__lambda', 0, 10.0, step = 0.0001),\n        'model__alpha':              trial.suggest_float('model__alpha', 0, 10.0, step = 0.0001),\n        'model__subsample':          trial.suggest_float('model__subsample', 0.4, 1.0, step = 0.0001),\n        'model__colsample_bytree':   trial.suggest_float('model__colsample_bytree', 0.4, 1.0, step = 0.0001),\n        'model__colsample_bylevel':  trial.suggest_float('model__colsample_bylevel', 0.4, 1.0, step = 0.0001),\n        'model__colsample_bynode':   trial.suggest_float('model__colsample_bynode', 0.4, 1.0, step = 0.0001)\n    }\n    pipeline_clone = clone(pipeline)\n    pipeline_clone.set_params(**params)\n\n    val_score = score_dataset(X, y, pipeline_clone)\n    return val_score\n\nstart_time = time.time()\nstudy = optuna.create_study(direction = 'minimize')\nstudy.optimize(xgb_objective, n_trials = 100)\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint(f\"XGB tuning took {elapsed_time:.2f} seconds.\")\nprint(elapsed_time)\n\nprint(study.best_params)\nprint(study.best_value)\nprint(study.best_trial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T08:05:02.496605Z","iopub.execute_input":"2025-01-18T08:05:02.496887Z","execution_failed":"2025-01-18T08:05:32.340Z"}},"outputs":[{"name":"stderr","text":"[I 2025-01-18 08:05:02,501] A new study created in memory with name: no-name-d91e400b-f0f2-47f7-bf8f-3322309db620\n[I 2025-01-18 08:05:05,721] Trial 0 finished with value: 0.31540859481270117 and parameters: {'model__n_estimators': 750, 'model__learning_rate': 0.0005511932936141188, 'model__max_depth': 3, 'model__min_child_weight': 8, 'model__lambda': 0.11660000000000001, 'model__alpha': 3.9617, 'model__subsample': 0.8061, 'model__colsample_bytree': 0.9622, 'model__colsample_bylevel': 0.41750000000000004, 'model__colsample_bynode': 0.45920000000000005}. Best is trial 0 with value: 0.31540859481270117.\n","output_type":"stream"},{"name":"stdout","text":"[-0.30044611 -0.33812794 -0.32852132 -0.3021699  -0.3077777 ]\n0.307777700132494\n0.0151359301710554\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-01-18 08:05:11,062] Trial 1 finished with value: 0.2671094044108245 and parameters: {'model__n_estimators': 550, 'model__learning_rate': 0.0014468134889327948, 'model__max_depth': 8, 'model__min_child_weight': 6, 'model__lambda': 8.168800000000001, 'model__alpha': 6.4327000000000005, 'model__subsample': 0.8436, 'model__colsample_bytree': 0.4349, 'model__colsample_bylevel': 0.8528, 'model__colsample_bynode': 0.901}. Best is trial 1 with value: 0.2671094044108245.\n","output_type":"stream"},{"name":"stdout","text":"[-0.24862678 -0.28812241 -0.28226385 -0.25549757 -0.26103641]\n0.26103640695823477\n0.015391730252390367\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-01-18 08:05:13,764] Trial 2 finished with value: 0.37795647068268734 and parameters: {'model__n_estimators': 950, 'model__learning_rate': 0.00015687466560882532, 'model__max_depth': 1, 'model__min_child_weight': 2, 'model__lambda': 4.505, 'model__alpha': 2.3133, 'model__subsample': 0.5064000000000001, 'model__colsample_bytree': 0.5426, 'model__colsample_bylevel': 0.4404, 'model__colsample_bynode': 0.7005}. Best is trial 1 with value: 0.2671094044108245.\n","output_type":"stream"},{"name":"stdout","text":"[-0.36499075 -0.40339983 -0.38915227 -0.36198025 -0.37025925]\n0.3702592495921705\n0.015844918165465124\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-01-18 08:05:17,834] Trial 3 finished with value: 0.1306446686874421 and parameters: {'model__n_estimators': 1050, 'model__learning_rate': 0.008919812485947802, 'model__max_depth': 3, 'model__min_child_weight': 9, 'model__lambda': 9.5759, 'model__alpha': 2.3312, 'model__subsample': 0.9245000000000001, 'model__colsample_bytree': 0.6960000000000001, 'model__colsample_bylevel': 0.7488, 'model__colsample_bynode': 0.6259}. Best is trial 3 with value: 0.1306446686874421.\n","output_type":"stream"},{"name":"stdout","text":"[-0.11887484 -0.13882098 -0.14237467 -0.12288653 -0.13026633]\n0.13026632671984703\n0.00898115438541487\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-01-18 08:05:21,432] Trial 4 finished with value: 0.31566825113991775 and parameters: {'model__n_estimators': 1650, 'model__learning_rate': 0.00038229819995605604, 'model__max_depth': 1, 'model__min_child_weight': 7, 'model__lambda': 7.961600000000001, 'model__alpha': 7.2029000000000005, 'model__subsample': 0.7339, 'model__colsample_bytree': 0.9515, 'model__colsample_bylevel': 0.5911000000000001, 'model__colsample_bynode': 0.9389000000000001}. Best is trial 3 with value: 0.1306446686874421.\n","output_type":"stream"},{"name":"stdout","text":"[-0.30082333 -0.33909486 -0.32918815 -0.3012185  -0.30801642]\n0.30801641637094573\n0.015616087096790241\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-01-18 08:05:31,969] Trial 5 finished with value: 0.14793579645458907 and parameters: {'model__n_estimators': 1350, 'model__learning_rate': 0.0022612942648834716, 'model__max_depth': 5, 'model__min_child_weight': 6, 'model__lambda': 1.5329000000000002, 'model__alpha': 1.9565000000000001, 'model__subsample': 0.5478000000000001, 'model__colsample_bytree': 0.9891000000000001, 'model__colsample_bylevel': 0.7275, 'model__colsample_bynode': 0.8204}. Best is trial 3 with value: 0.1306446686874421.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# def rf_objective(trial):  \n    \n#     params = {\n#         'model__random_state':          SEED,\n#         'model__n_estimators':          trial.suggest_int('model__n_estimators', 500, 10000, step = 100),\n#         'model__max_depth':             trial.suggest_categorical('model__max_depth', [None] + list(range(4, 9))),\n#         'model__min_samples_split':     trial.suggest_int('model__min_samples_split', 2, 20),\n#         'model__min_samples_leaf':      trial.suggest_int('model__min_samples_leaf', 1, 20),\n#         'model__max_features':          trial.suggest_categorical('model__max_features', [\"sqrt\", \"log2\", None]),\n#         'model__min_impurity_decrease': trial.suggest_categorical('model__min_impurity_decrease',\n#                                                                   [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n#     }\n#     pipeline_clone = clone(pipeline)\n#     pipeline_clone.set_params(**params)\n\n#     val_score = score_dataset(X, y, pipeline_clone)\n#     return val_score\n\n# start_time = time.time()\n# study = optuna.create_study(direction = 'minimize')\n# study.optimize(rf_objective, n_trials = 100)\n# end_time = time.time()\n# elapsed_time = end_time - start_time\n# print(f\"RF tuning took {elapsed_time:.2f} seconds.\")\n# print(elapsed_time)\n\n# print(study.best_params)\n# print(study.best_value)\n# print(study.best_trial)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# best_params = {'model__n_estimators': 650, 'model__learning_rate': 0.02384699181391458, \n#                'model__max_depth': 4, 'model__min_child_weight': 1, \n#                'model__lambda': 3.6219467321680083, 'model__alpha': 0.00555739253376164,\n#                'model__subsample': 0.5767916833020451, 'model__colsample_bytree': 0.799700431685384, \n#                'model__colsample_bylevel': 0.8676463787826333, 'model__colsample_bynode': 0.8271978509268489}\n\n# Best is trial 62 finished with value: 0.11742375540973124 \n# [-0.10837224 -0.12998627 -0.12850005 -0.10610519 -0.11415502]\n# 0.11415502442730315\n# 0.010012248568044236\n\n# # Best params\n# best_params = {'model__n_estimators': 9000, 'model__learning_rate': 0.002221965665898899, \n#                'model__max_depth': 4, 'model__min_child_weight': 5, \n#                'model__lambda': 0.3279, 'model__alpha': 0.2417, \n#                'model__subsample': 0.8049000000000001, 'model__colsample_bytree': 0.9475, \n#                'model__colsample_bylevel': 0.4768, 'model__colsample_bynode': 0.4454}\n\n# Best is trial 92 with value: 0.11728844905814861.\n# [-0.1069524  -0.12825763 -0.12633835 -0.10719973 -0.11769413]\n# 0.11769413498310685\n# 0.009066468479194328\n\n# best_params = {'model__n_estimators': 1000, 'model__learning_rate': 0.02384699181391458, \n#                'model__max_depth': 4, 'model__min_child_weight': 1, \n#                'model__lambda': 3.6219467321680083, 'model__alpha': 0.00555739253376164,\n#                'model__subsample': 0.5767916833020451, 'model__colsample_bytree': 0.799700431685384, \n#                'model__colsample_bylevel': 0.8676463787826333, 'model__colsample_bynode': 0.8271978509268489}\n\n# [-0.10795649 -0.13002858 -0.12830252 -0.10569348 -0.11434615]\n# 0.11434615405227047\n# 0.010137099509793399\n# 0.11726544444298999","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with Age_since_mod feature\n\n# best_params = {'model__n_estimators': 850, 'model__learning_rate': 0.017442598532274846, \n#                'model__max_depth': 4, 'model__min_child_weight': 1, \n#                'model__lambda': 0.8255067561921624, 'model__alpha': 0.004278929472964361, \n#                'model__subsample': 0.8974473156207723, 'model__colsample_bytree': 0.6523619866997316, \n#                'model__colsample_bylevel': 0.996362051631553, 'model__colsample_bynode': 0.4628476409826708}\n\n# Best is trial 61 with value: 0.11779737989132073.\n# [-0.10790906 -0.1318243  -0.12853275 -0.10425928 -0.11646151]\n# 0.11646151088245223\n# 0.010907303679586703","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with pipeline2\n\n# best_params = {'model__n_estimators': 1000, 'model__learning_rate': 0.020124989124474368, \n#                'model__max_depth': 4, 'model__min_child_weight': 6, \n#                'model__lambda': 1.732780164845022, 'model__alpha': 0.03214159796407795, \n#                'model__subsample': 0.618267265549825, 'model__colsample_bytree': 0.7018360769686597, \n#                'model__colsample_bylevel': 0.5343572892012461, 'model__colsample_bynode': 0.9702456455515944}\n\n#Best is trial 85 with value: 0.11782913284946137.\n# [-0.1100461  -0.12623955 -0.12463757 -0.11017505 -0.1180474 ]\n# 0.11804740104228104\n# 0.0068745661426423185\n\n\n# best_params = {'model__n_estimators': 8500, 'model__learning_rate': 0.0024356711073752263, \n#                'model__max_depth': 6, 'model__min_child_weight': 7, \n#                'model__lambda': 1.0561, 'model__alpha': 0.0106, \n#                'model__subsample': 0.7481, 'model__colsample_bytree': 0.6855, \n#                'model__colsample_bylevel': 0.8596, 'model__colsample_bynode': 0.7395}\n\n# Best is trial 86 with value: 0.11844810379526453.\n# [-0.11185226 -0.12871867 -0.12804039 -0.10766969 -0.11595951]\n# 0.11595951124551873\n# 0.008524891860194693\n\n\n# best_params = {'model__n_estimators': 1600, 'model__learning_rate': 0.020124989124474368, \n#                'model__max_depth': 4, 'model__min_child_weight': 6, \n#                'model__lambda': 1.732780164845022, 'model__alpha': 0.03214159796407795, \n#                'model__subsample': 0.618267265549825, 'model__colsample_bytree': 0.7018360769686597, \n#                'model__colsample_bylevel': 0.5343572892012461, 'model__colsample_bynode': 0.9702456455515944}\n\n# pipeline 2\n# 0.11802772081955834  2000\n# 0.11790519839005424  1800\n# 0.11783945720039994  1700\n# 0.11775646400190418  1600\n# 0.11777810773615957  1500\n# 0.11777453916635619  1400\n# 0.11776996564553088  1300\n# 0.1177948484577633   1200","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Best params\n# with pipeline3\n\n# best_params = {'model__n_estimators': 800, 'model__learning_rate': 0.03224043015635982, \n#                'model__max_depth': 4, 'model__min_child_weight': 0, \n#                'model__lambda': 1.888402035590375, 'model__alpha': 0.01316645967800336, \n#                'model__subsample': 0.7195499210117768, 'model__colsample_bytree': 0.9291979069424845, \n#                'model__colsample_bylevel': 0.41676523400723603, 'model__colsample_bynode': 0.8500081595906049}\n\n# Best is trial 66 with value: 0.11661104365392565.\n# [-0.10954966 -0.12933787 -0.1275082  -0.10417967 -0.11247982]\n# 0.11247981940875118\n# 0.010021866508966784\n\n# best_params = {'model__n_estimators': 2300, 'model__learning_rate': 0.01796267061260535, \n#                'model__max_depth': 3, 'model__min_child_weight': 1, \n#                'model__lambda': 4.547000000000001, 'model__alpha': 0.2436, \n#                'model__subsample': 0.5405, 'model__colsample_bytree': 0.7052, \n#                'model__colsample_bylevel': 0.8729, 'model__colsample_bynode': 0.7699}\n\n# Best is trial 83 with value: 0.11711228199833161.\n# [-0.10811146 -0.12430323 -0.12678496 -0.10884254 -0.11751923]\n# 0.11751922891170936\n# 0.0076790551766297965","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #pipeline 4 best params\n# {'model__n_estimators': 500, 'model__max_depth': None, \n#  'model__min_samples_split': 4, 'model__min_samples_leaf': 1, \n#  'model__max_features': None, 'model__min_impurity_decrease': 1e-05}\n\n# Best is trial 69 with value: 0.13452078571895393.\n# [-0.13265846 -0.14837583 -0.13993977 -0.12230483 -0.12932503]\n# 0.13265846285872251\n# 0.00895568242880693","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pipeline.set_params(**best_params)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.341Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CV Score","metadata":{}},{"cell_type":"code","source":"# score_dataset(X, y, pipeline)\n# 0.11742375540973124\n# public score : 0.12053\n\n# 0.11779737989132073  best param with Age_since_mod feature\n# public score : 0.12179\n\n# 0.11782913284946137 best param with pipeline2\n# public score : 0.12119\n\n# 0.11661104365392565 best param with pipeline3\n# public score : 0.12261\n\n# 0.11726544444298999 pipeline1 with 1000 iter\n# public score : 0.12090\n\n# pipeline 2\n# 0.11802772081955834  2000\n# 0.11790519839005424  1800\n# 0.11783945720039994  1700\n# 0.11775646400190418  1600\n# 0.11777810773615957  1500\n# 0.11777453916635619  1400\n# 0.11776996564553088  1300\n# 0.1177948484577633   1200","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.342Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train on full data and obtain test predictions","metadata":{}},{"cell_type":"code","source":"#retrain on full data and obtain test predictions using best model hyperparameter values\npipeline.fit(X, np.log(y))\n\n# Preprocessing of validation data, get predictions\npred = np.exp(pipeline.predict(X_test))\n\nprint(pred[:10])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipeline","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': pred})\noutput.to_csv('submission.csv', index=False)\nprint('saved output file')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T08:05:32.342Z"}},"outputs":[],"execution_count":null}]}